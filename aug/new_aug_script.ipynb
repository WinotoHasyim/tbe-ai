{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1a6e3d7",
   "metadata": {},
   "source": [
    "# Bulir Padi Segmentation: Advanced Augmentation Pipeline\n",
    "\n",
    "This notebook extends the original Roboflow data loading and copy-paste augmentation with a more advanced, offline augmentation pipeline. The key additions are:\n",
    "\n",
    "1.  **Conditional Tiling**: High-resolution images are tiled to handle large inputs effectively.\n",
    "2.  **Randomized Augmentations**: A variety of geometric, color, and structural augmentations are applied randomly to increase dataset variance.\n",
    "3.  **Dataset Expansion**: The training set is expanded by a configurable factor (e.g., 5x).\n",
    "4.  **Detailed Logging**: The process generates a summary of augmentations and class distributions.\n",
    "\n",
    "The original copy-paste logic for class balancing is preserved and will run *after* this new pipeline has expanded the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa919b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"ultralytics<=8.3.40\" supervision roboflow pandas\n",
    "# prevent ultralytics from tracking your activity\n",
    "!yolo settings sync=False\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ba00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# Note: You may need to authenticate Roboflow here if you haven't already.\n",
    "# !roboflow login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1b691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p {HOME}/datasets\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# --- IMPORTANT: SET YOUR ROBOFLOW CREDENTIALS ---\n",
    "# Option 1: If using Google Colab, use userdata secrets.\n",
    "from google.colab import userdata\n",
    "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
    "\n",
    "# Option 2: Paste your API key directly (less secure).\n",
    "# ROBOFLOW_API_KEY = \"YOUR_ROBOFLOW_API_KEY\" # <-- PASTE YOUR KEY HERE\n",
    "\n",
    "if ROBOFLOW_API_KEY == \"YOUR_ROBOFLOW_API_KEY\":\n",
    "    print(\"ERROR: Please replace 'YOUR_ROBOFLOW_API_KEY' with your actual Roboflow API key.\")\n",
    "else:\n",
    "    rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "    workspace = rf.workspace(\"tbe\") # Your workspace ID\n",
    "    project = workspace.project(\"rice-grain-svjri\") # Your project ID\n",
    "    version = project.version(15)\n",
    "    dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e4d28",
   "metadata": {},
   "source": [
    "## Section 1: Pre-Augmentation Setup & Utilities\n",
    "\n",
    "This section contains all the necessary imports, configurations, and helper functions for the new augmentation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1384ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install library for augmentation\n",
    "%pip install albumentations opencv-python-headless scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Imports for Tiling, Augmentation, and Logging\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import yaml\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "# --- Configuration for New Augmentation Pipeline ---\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "SEED = 42\n",
    "\n",
    "# 1. Preprocessing - Conditional Tiling\n",
    "TILING_THRESHOLD = 1500  # Tile images with width or height > 1500px\n",
    "TILE_SIZE = (640, 640)   # Size of each tile\n",
    "TILE_OVERLAP = 0.1       # 10% overlap between tiles\n",
    "\n",
    "# 2. Dataset Expansion\n",
    "EXPANSION_FACTOR = 5  # Target: 5x the original dataset size\n",
    "\n",
    "# 3. Randomized Augmentation Logic\n",
    "NUM_AUGMENTATIONS_MIN = 3 # Min number of augmentations to apply per image\n",
    "NUM_AUGMENTATIONS_MAX = 5 # Max number of augmentations to apply per image\n",
    "\n",
    "print(\"Configuration for Tiling and Augmentation pipeline is set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b14798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions for Mask and Annotation Conversion ---\n",
    "\n",
    "def yolo_to_masks(annotation_path, img_height, img_width):\n",
    "    \"\"\"Reads YOLO segmentation format and converts it to a list of binary masks.\"\"\"\n",
    "    masks = []\n",
    "    class_ids = []\n",
    "    if not Path(annotation_path).exists():\n",
    "        return masks, class_ids\n",
    "\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) > 1:\n",
    "                class_id = int(parts[0])\n",
    "                poly = np.array(parts[1:], dtype=np.float32).reshape(-1, 2)\n",
    "                poly[:, 0] *= img_width\n",
    "                poly[:, 1] *= img_height\n",
    "                poly = poly.astype(np.int32)\n",
    "\n",
    "                mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "                cv2.fillPoly(mask, [poly], 1)\n",
    "                masks.append(mask)\n",
    "                class_ids.append(class_id)\n",
    "    return masks, class_ids\n",
    "\n",
    "def masks_to_yolo(masks, class_ids, img_height, img_width):\n",
    "    \"\"\"Converts a list of binary masks back to YOLO segmentation format.\"\"\"\n",
    "    annotations = []\n",
    "    for i, mask in enumerate(masks):\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        # Pad mask to avoid issues at edges\n",
    "        padded_mask = np.pad(mask, pad_width=1, mode='constant', constant_values=0)\n",
    "        contours = find_contours(padded_mask, 0.5)\n",
    "\n",
    "        if not contours:\n",
    "            continue\n",
    "        # Use the largest contour\n",
    "        contour = max(contours, key=len)\n",
    "        # Revert padding effect\n",
    "        contour -= 1\n",
    "        \n",
    "        # YOLO format requires x, y coordinates\n",
    "        # find_contours returns y, x, so we flip them\n",
    "        contour = np.flip(contour, axis=1)\n",
    "\n",
    "        if len(contour) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Normalize\n",
    "        contour = contour.astype(np.float32)\n",
    "        contour[:, 0] /= img_width\n",
    "        contour[:, 1] /= img_height\n",
    "        \n",
    "        contour = np.clip(contour, 0.0, 1.0)\n",
    "\n",
    "        yolo_coords = ' '.join([f'{coord:.6f}' for coord in contour.flatten()])\n",
    "        annotations.append(f\"{int(class_ids[i])} {yolo_coords}\")\n",
    "    return annotations\n",
    "\n",
    "print(\"Mask and YOLO annotation conversion utilities are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Preprocessing and Augmentation Functions ---\n",
    "\n",
    "def tile_if_highres(image, masks):\n",
    "    \"\"\"Performs tiling only on high-resolution images.\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    if width <= TILING_THRESHOLD and height <= TILING_THRESHOLD:\n",
    "        return [(image, masks)], False  # Return original as a single-item list\n",
    "\n",
    "    tiled_data = []\n",
    "    tile_w, tile_h = TILE_SIZE\n",
    "    step_w = int(tile_w * (1 - TILE_OVERLAP))\n",
    "    step_h = int(tile_h * (1 - TILE_OVERLAP))\n",
    "\n",
    "    for y in range(0, height, step_h):\n",
    "        for x in range(0, width, step_w):\n",
    "            x1, y1 = x, y\n",
    "            x2, y2 = min(x + tile_w, width), min(y + tile_h, height)\n",
    "\n",
    "            # Skip tiles that are too small\n",
    "            if (x2 - x1) < tile_w / 2 or (y2 - y1) < tile_h / 2:\n",
    "                continue\n",
    "\n",
    "            tile_img = image[y1:y2, x1:x2]\n",
    "            tile_masks = [m[y1:y2, x1:x2] for m in masks]\n",
    "\n",
    "            # Only keep tiles that contain at least part of an object\n",
    "            if any(np.sum(m) > 0 for m in tile_masks):\n",
    "                tiled_data.append((tile_img, tile_masks))\n",
    "\n",
    "    return tiled_data, True\n",
    "\n",
    "def get_augmentation_pipelines():\n",
    "    \"\"\"Defines augmentation pipelines in the order: geometric → affine → structural → color → noise_blur\"\"\"\n",
    "    \n",
    "    pipelines = {\n",
    "        # Resizing / Cropping (always applied first, not counted in random selection)\n",
    "        'cropping': A.Compose([\n",
    "            A.SmallestMaxSize(max_size=TILE_SIZE[0], p=1.0),\n",
    "            A.RandomSizedCrop(\n",
    "                min_max_height=(int(TILE_SIZE[0]*0.6), TILE_SIZE[0]),\n",
    "                height=TILE_SIZE[0],\n",
    "                width=TILE_SIZE[1],\n",
    "                p=1.0\n",
    "            )\n",
    "        ], p=1.0, seed=SEED),\n",
    "\n",
    "        # Step 1: Geometric\n",
    "        'geometric': A.Compose([\n",
    "            A.HorizontalFlip(p=1.0),\n",
    "            A.VerticalFlip(p=1.0),\n",
    "            A.RandomRotate90(p=1.0)\n",
    "        ], p=1.0, seed=SEED),\n",
    "\n",
    "        # Step 2: Affine / Perspective\n",
    "        'affine': A.Compose([\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.15, scale_limit=0.2, rotate_limit=20, p=1.0\n",
    "            ),\n",
    "            A.Affine(shear=(-10, 10), p=1.0),\n",
    "            A.Perspective(scale=(0.05, 0.15), keep_size=True, p=1.0)\n",
    "        ], p=1.0, seed=SEED),\n",
    "\n",
    "        # Step 3: Dropout / occlusion\n",
    "        'structural': A.Compose([\n",
    "            A.CoarseDropout(\n",
    "                num_holes_range=(1, 8),\n",
    "                hole_height_range=(0.02, 0.1),\n",
    "                hole_width_range=(0.02, 0.1),\n",
    "                fill=0,\n",
    "                fill_mask=None,\n",
    "                p=1.0\n",
    "            ),\n",
    "            A.GridDistortion(p=1.0),\n",
    "            A.RandomErasing(p=1.0, scale=(0.02, 0.1), ratio=(0.3, 3.3))\n",
    "        ], p=1.0, seed=SEED),\n",
    "\n",
    "        # Step 4: Color\n",
    "        'color': A.Compose([\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
    "            A.HueSaturationValue(hue_shift_limit=0, sat_shift_limit=30, val_shift_limit=20, p=1.0),\n",
    "            A.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=1.0),\n",
    "        ], p=1.0, seed=SEED),\n",
    "\n",
    "        # Step 5: Noise / Blur\n",
    "        'noise_blur': A.Compose([\n",
    "            A.GaussNoise(std_range=(0.04, 0.2), mean_range=(0.0, 0.0), per_channel=True, noise_scale_factor=1.0, p=1.0),\n",
    "            A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "            A.ISONoise(p=1.0)\n",
    "        ], p=1.0, seed=SEED),\n",
    "    }\n",
    "    \n",
    "    return pipelines\n",
    "\n",
    "def apply_random_augmentations(image, masks, pipelines):\n",
    "    \"\"\"\n",
    "    Applies resizing/cropping first, then randomly selects 3-5 categories from the step_order.\n",
    "    For each selected category, only one transform from that category is applied.\n",
    "    \"\"\"\n",
    "    # --- Always apply resizing / cropping first ---\n",
    "    cropped = pipelines['cropping'](image=image, masks=masks)\n",
    "    augmented_image = cropped['image']\n",
    "    augmented_masks = cropped['masks']\n",
    "\n",
    "    # Step order\n",
    "    step_order = ['geometric', 'affine', 'structural', 'color', 'noise_blur']\n",
    "\n",
    "    # Randomly pick 3-5 categories\n",
    "    num_to_apply = random.randint(NUM_AUGMENTATIONS_MIN, NUM_AUGMENTATIONS_MAX)\n",
    "    chosen_categories = random.sample(step_order, num_to_apply)\n",
    "\n",
    "    applied_augs = []\n",
    "\n",
    "    # Apply each chosen category in step_order\n",
    "    for category in step_order:\n",
    "        if category in chosen_categories:\n",
    "            transforms = pipelines[category].transforms\n",
    "            if transforms:\n",
    "                # Randomly pick ONE transform from the category\n",
    "                transform_to_apply = random.choice(transforms)\n",
    "                temp_pipeline = A.Compose([transform_to_apply])\n",
    "                transformed = temp_pipeline(image=augmented_image, masks=augmented_masks)\n",
    "                augmented_image = transformed['image']\n",
    "                augmented_masks = transformed['masks']\n",
    "                applied_augs.append(transform_to_apply.__class__.__name__)\n",
    "\n",
    "    return augmented_image, augmented_masks, applied_augs\n",
    "\n",
    "print(\"Core preprocessing and augmentation functions are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f47700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Logging and Summary Function ---\n",
    "\n",
    "def log_augmentation_stats(stats, output_dir):\n",
    "    \"\"\"Generates and saves a summary of the augmentation process.\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    summary = {}\n",
    "\n",
    "    # 1. Dataset Size\n",
    "    summary['Dataset Size'] = {\n",
    "        'Before': stats['initial_image_count'],\n",
    "        'After': stats['final_image_count']\n",
    "    }\n",
    "\n",
    "    # 2. Per-class Counts\n",
    "    class_names = stats['class_names']\n",
    "    summary['Class Counts Before'] = {class_names[i]: count for i, count in stats['initial_class_counts'].items()}\n",
    "    summary['Class Counts After'] = {class_names[i]: count for i, count in stats['final_class_counts'].items()}\n",
    "\n",
    "    # 3. Augmentation Frequency\n",
    "    total_augs = sum(stats['augmentation_freq'].values())\n",
    "    summary['Augmentation Frequency'] = {\n",
    "        aug: {\n",
    "            'Count': count,\n",
    "            'Percentage': f\"{(count / total_augs * 100):.2f}%\" if total_augs > 0 else \"0.00%\"\n",
    "        } for aug, count in sorted(stats['augmentation_freq'].items())\n",
    "    }\n",
    "    summary['Tiling Info'] = {\n",
    "        'Images Tiled': stats['tiling_info']['images_tiled'],\n",
    "        'Total Tiles Generated': stats['tiling_info']['tiles_generated']\n",
    "    }\n",
    "\n",
    "    # --- Print Summary Table ---\n",
    "    print(\"\\n--- Augmentation Summary ---\")\n",
    "    print(f\"Dataset Size: {summary['Dataset Size']['Before']} -> {summary['Dataset Size']['After']}\")\n",
    "    \n",
    "    df_classes = pd.DataFrame([\n",
    "        summary['Class Counts Before'], \n",
    "        summary['Class Counts After']\n",
    "    ], index=['Before', 'After']).T\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    print(df_classes.to_string())\n",
    "    \n",
    "    df_augs = pd.DataFrame.from_dict(summary['Augmentation Frequency'], orient='index')\n",
    "    print(\"\\nAugmentation Frequency:\")\n",
    "    print(df_augs.to_string())\n",
    "    \n",
    "    print(f\"\\nImages Tiled: {summary['Tiling Info']['Images Tiled']}\")\n",
    "    print(f\"Total Tiles Generated: {summary['Tiling Info']['Total Tiles Generated']}\")\n",
    "\n",
    "    # --- Save to CSV ---\n",
    "    csv_path = output_dir / 'augmentation_summary.csv'\n",
    "    try:\n",
    "        df_summary = pd.concat([df_classes.T, df_augs.T]).T\n",
    "        df_summary.to_csv(csv_path)\n",
    "        print(f\"\\nSummary saved to {csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCould not save summary CSV: {e}\")\n",
    "\n",
    "    return summary\n",
    "\n",
    "print(\"Logging and summary function is defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ab630",
   "metadata": {},
   "source": [
    "## Section 2: Main Augmentation Pipeline Execution\n",
    "\n",
    "This is the main execution block. It performs the following steps:\n",
    "1.  Backs up the original training data.\n",
    "2.  Calculates the target number of images for expansion.\n",
    "3.  Iterates through the original dataset, applying tiling and random augmentations.\n",
    "4.  Saves the newly generated images, masks, and metadata to a temporary directory.\n",
    "5.  Overwrites the original training data with the augmented data.\n",
    "6.  Logs the final statistics.\n",
    "\n",
    "**Note:** This process will modify your dataset in place. The backup is created in `train_original_backup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b684812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths from Roboflow download\n",
    "if 'dataset' in globals():\n",
    "    DATASET_PATH = Path(dataset.location).resolve()\n",
    "else:\n",
    "    # Fallback if the Roboflow cell was skipped\n",
    "    DATASET_PATH = Path(f\"{HOME}/datasets/Rice-Grain-svjri-15\").resolve()\n",
    "    print(f\"WARNING: Roboflow 'dataset' object not found. Using fallback path: {DATASET_PATH}\")\n",
    "\n",
    "DATA_CONFIG_PATH = DATASET_PATH / \"data.yaml\"\n",
    "if not DATA_CONFIG_PATH.exists():\n",
    "    raise FileNotFoundError(f\"data.yaml not found at {DATA_CONFIG_PATH}. Please ensure the dataset was downloaded correctly.\")\n",
    "\n",
    "# Load data config\n",
    "with open(DATA_CONFIG_PATH, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "CLASS_NAMES = data_config['names']\n",
    "\n",
    "TRAIN_IMAGES_PATH = DATASET_PATH / data_config['train']\n",
    "TRAIN_LABELS_PATH = TRAIN_IMAGES_PATH.parent / 'labels'\n",
    "\n",
    "print(f\"Dataset Location: {DATASET_PATH}\")\n",
    "print(f\"Train Images Path: {TRAIN_IMAGES_PATH}\")\n",
    "print(f\"Train Labels Path: {TRAIN_LABELS_PATH}\")\n",
    "print(f\"Class Names: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e35b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution Block ---\n",
    "print(\"Starting the advanced augmentation and dataset expansion process...\")\n",
    "\n",
    "# 1. Backup original data\n",
    "original_images_path = TRAIN_IMAGES_PATH\n",
    "original_labels_path = TRAIN_LABELS_PATH\n",
    "backup_images_path = DATASET_PATH / 'train_original_backup' / 'images'\n",
    "backup_labels_path = DATASET_PATH / 'train_original_backup' / 'labels'\n",
    "\n",
    "if not backup_images_path.exists() and original_images_path.exists():\n",
    "    print(\"Backing up original training data...\")\n",
    "    shutil.copytree(original_images_path, backup_images_path)\n",
    "    shutil.copytree(original_labels_path, backup_labels_path)\n",
    "    print(f\"Backup complete in {DATASET_PATH / 'train_original_backup'}\")\n",
    "else:\n",
    "    print(\"Backup already exists or source is missing. Using existing backup as source.\")\n",
    "    original_images_path = backup_images_path\n",
    "    original_labels_path = backup_labels_path\n",
    "\n",
    "# 2. Prepare temporary directory for augmented data\n",
    "temp_aug_images_path = DATASET_PATH / 'train_augmented_temp' / 'images'\n",
    "temp_aug_labels_path = DATASET_PATH / 'train_augmented_temp' / 'labels'\n",
    "shutil.rmtree(temp_aug_images_path.parent, ignore_errors=True)\n",
    "temp_aug_images_path.mkdir(parents=True, exist_ok=True)\n",
    "temp_aug_labels_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 3. Initialize stats and pipelines\n",
    "image_files = sorted(list(original_images_path.glob('*.jpg')) + list(original_images_path.glob('*.png')))\n",
    "initial_image_count = len(image_files)\n",
    "target_image_count = initial_image_count * EXPANSION_FACTOR\n",
    "\n",
    "stats = {\n",
    "    'initial_image_count': initial_image_count,\n",
    "    'final_image_count': 0,\n",
    "    'class_names': CLASS_NAMES,\n",
    "    'initial_class_counts': Counter(),\n",
    "    'final_class_counts': Counter(),\n",
    "    'augmentation_freq': Counter(),\n",
    "    'tiling_info': {'images_tiled': 0, 'tiles_generated': 0}\n",
    "}\n",
    "pipelines = get_augmentation_pipelines()\n",
    "\n",
    "# 4. Main Augmentation Loop\n",
    "pbar = tqdm(total=target_image_count, desc=\"Generating Augmented Data\")\n",
    "generated_count = 0\n",
    "\n",
    "# First pass: collect initial stats\n",
    "for img_path in image_files:\n",
    "    label_path = original_labels_path / f\"{img_path.stem}.txt\"\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            stats['initial_class_counts'][int(line.split()[0])] += 1\n",
    "    # Also copy original files to the new location\n",
    "    shutil.copy(img_path, temp_aug_images_path)\n",
    "    shutil.copy(label_path, temp_aug_labels_path)\n",
    "    generated_count += 1\n",
    "    pbar.update(1)\n",
    "\n",
    "# Second pass: generate new augmented images until target is reached\n",
    "while generated_count < target_image_count:\n",
    "    img_path = random.choice(image_files)\n",
    "    label_path = original_labels_path / f\"{img_path.stem}.txt\"\n",
    "\n",
    "    image = cv2.imread(str(img_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    masks, class_ids = yolo_to_masks(label_path, height, width)\n",
    "    if not masks:\n",
    "        continue\n",
    "\n",
    "    # Step 1: Conditional Tiling\n",
    "    tiled_data, was_tiled = tile_if_highres(image, masks)\n",
    "    if was_tiled:\n",
    "        stats['tiling_info']['images_tiled'] += 1\n",
    "        stats['tiling_info']['tiles_generated'] += len(tiled_data)\n",
    "\n",
    "    # Process each tile (or the original image if not tiled)\n",
    "    for i, (tile_img, tile_masks) in enumerate(tiled_data):\n",
    "        if generated_count >= target_image_count: break\n",
    "\n",
    "        # Step 2: Random Augmentations\n",
    "        aug_img, aug_masks, applied_augs = apply_random_augmentations(tile_img, tile_masks, pipelines)\n",
    "        \n",
    "        # Update stats\n",
    "        for aug_name in applied_augs:\n",
    "            stats['augmentation_freq'][aug_name] += 1\n",
    "\n",
    "        # Step 3: Save augmented data\n",
    "        new_stem = f\"{img_path.stem}_aug_{generated_count}\"\n",
    "        if was_tiled: new_stem += f\"_tile_{i}\"\n",
    "\n",
    "        new_img_path = temp_aug_images_path / f\"{new_stem}.jpg\"\n",
    "        new_label_path = temp_aug_labels_path / f\"{new_stem}.txt\"\n",
    "        new_meta_path = temp_aug_labels_path / f\"{new_stem}.json\"\n",
    "\n",
    "        aug_height, aug_width = aug_img.shape[:2]\n",
    "        yolo_annotations = masks_to_yolo(aug_masks, class_ids, aug_height, aug_width)\n",
    "\n",
    "        if yolo_annotations:\n",
    "            cv2.imwrite(str(new_img_path), cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
    "            with open(new_label_path, 'w') as f:\n",
    "                f.write('\\n'.join(yolo_annotations))\n",
    "            \n",
    "            metadata = {\n",
    "                'original_image': img_path.name,\n",
    "                'tiling_applied': was_tiled,\n",
    "                'applied_augmentations': applied_augs\n",
    "            }\n",
    "            with open(new_meta_path, 'w') as f:\n",
    "                json.dump(metadata, f, indent=4)\n",
    "            \n",
    "            generated_count += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# 5. Overwrite original data with augmented data\n",
    "print(\"\\nReplacing original training data with augmented version...\")\n",
    "shutil.rmtree(TRAIN_IMAGES_PATH)\n",
    "shutil.rmtree(TRAIN_LABELS_PATH)\n",
    "shutil.move(str(temp_aug_images_path), str(TRAIN_IMAGES_PATH))\n",
    "shutil.move(str(temp_aug_labels_path), str(TRAIN_LABELS_PATH))\n",
    "shutil.rmtree(temp_aug_images_path.parent) # Clean up temp parent folder\n",
    "print(\"Dataset overwrite complete.\")\n",
    "\n",
    "# 6. Final Stats Calculation and Logging\n",
    "final_image_files = list(TRAIN_IMAGES_PATH.glob('*.jpg'))\n",
    "stats['final_image_count'] = len(final_image_files)\n",
    "for label_file in TRAIN_LABELS_PATH.glob('*.txt'):\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            stats['final_class_counts'][int(line.split()[0])] += 1\n",
    "\n",
    "log_augmentation_stats(stats, DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f47701",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Original Copy-Paste Augmentation for Class Balancing\n",
    "\n",
    "The following cells contain the **original, untouched** copy-paste augmentation logic. This code will now run on the newly expanded and augmented dataset created in the previous section.\n",
    "\n",
    "Its purpose is to perform a final balancing pass, specifically targeting the minority class by copying its instances onto other images.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81798dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# Fungsi untuk membaca annotation YOLO format\n",
    "def read_yolo_annotation(annotation_path):\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        annotations = []\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) > 0:\n",
    "                class_id = int(parts[0])\n",
    "                coords = [float(x) for x in parts[1:]]\n",
    "                annotations.append([class_id] + coords)\n",
    "    return annotations\n",
    "\n",
    "# Fungsi untuk menulis annotation YOLO format\n",
    "def write_yolo_annotation(annotation_path, annotations):\n",
    "    with open(annotation_path, 'w') as f:\n",
    "        for ann in annotations:\n",
    "            class_id = int(ann[0])\n",
    "            coords = ' '.join([f'{x:.6f}' for x in ann[1:]])\n",
    "            f.write(f'{class_id} {coords}\\n')\n",
    "\n",
    "# Fungsi untuk membaca konfigurasi dataset dari YAML\n",
    "def load_data_config(data_yaml_path, dataset_path_hint=None):\n",
    "    data_yaml_path = Path(data_yaml_path)\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "\n",
    "    names = data.get('names', [])\n",
    "    if isinstance(names, dict):\n",
    "        names = [names[str(i)] for i in range(len(names))]\n",
    "\n",
    "    if dataset_path_hint:\n",
    "        base_dir = Path(dataset_path_hint).resolve()\n",
    "    else:\n",
    "        base_dir = data_yaml_path.parent.resolve()\n",
    "\n",
    "    def resolve_path(path_value: str | Path):\n",
    "        path_value = Path(path_value)\n",
    "        if path_value.is_absolute():\n",
    "            return path_value.resolve()\n",
    "        parts = []\n",
    "        for part in path_value.parts:\n",
    "            if part == '..':\n",
    "                if parts:\n",
    "                    parts.pop()\n",
    "            elif part != '.':\n",
    "                parts.append(part)\n",
    "        normalized = Path(*parts) if parts else Path('.')\n",
    "        resolved = (base_dir / normalized).resolve()\n",
    "        return resolved\n",
    "\n",
    "    splits = {}\n",
    "    for split_key in ('train', 'val', 'test'):\n",
    "        split_path = data.get(split_key)\n",
    "        if not split_path:\n",
    "            continue\n",
    "        images_dir = resolve_path(split_path)\n",
    "        labels_dir = (images_dir.parent / 'labels').resolve()\n",
    "        splits[split_key] = {\n",
    "            'images': images_dir,\n",
    "            'labels': labels_dir,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        'names': names,\n",
    "        'splits': splits,\n",
    "    }\n",
    "\n",
    "# Menghitung distribusi kelas dan statistik per gambar\n",
    "def collect_class_stats(labels_dir, num_classes):\n",
    "    labels_dir = Path(labels_dir)\n",
    "    counts = Counter({cls: 0 for cls in range(num_classes)})\n",
    "    image_stats = {}\n",
    "\n",
    "    for label_path in labels_dir.glob('*.txt'):\n",
    "        annotations = read_yolo_annotation(label_path)\n",
    "        per_image = Counter({cls: 0 for cls in range(num_classes)})\n",
    "        for ann in annotations:\n",
    "            class_id = int(ann[0])\n",
    "            if class_id >= num_classes:\n",
    "                continue\n",
    "            per_image[class_id] += 1\n",
    "            counts[class_id] += 1\n",
    "        image_stats[label_path.stem] = per_image\n",
    "\n",
    "    return counts, image_stats\n",
    "\n",
    "# Menampilkan distribusi kelas yang mudah dibaca\n",
    "def print_class_distribution(split_name, counts, class_names):\n",
    "    total = sum(counts.values())\n",
    "    print(f\"\\nDistribusi kelas untuk {split_name}:\")\n",
    "    for idx, class_name in enumerate(class_names):\n",
    "        value = counts.get(idx, 0)\n",
    "        if total > 0:\n",
    "            pct = (value / total) * 100\n",
    "            print(f\"  - {class_name}: {value} ({pct:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"  - {class_name}: {value}\")\n",
    "\n",
    "# Menentukan rencana augmentasi agar kelas minoritas mendekati jumlah kelas mayoritas\n",
    "def build_balanced_augmentation_plan(image_stats, target_class_id, deficit, max_aug_per_image=5):\n",
    "    plan = {}\n",
    "    if deficit <= 0:\n",
    "        return plan\n",
    "\n",
    "    eligible = []\n",
    "    for stem, stats in image_stats.items():\n",
    "        instances = stats.get(target_class_id, 0)\n",
    "        if instances > 0:\n",
    "            eligible.append((stem, instances))\n",
    "\n",
    "    if not eligible:\n",
    "        return plan\n",
    "\n",
    "    eligible.sort(key=lambda item: item[1], reverse=True)\n",
    "    total_capacity = sum(instances * max_aug_per_image for _, instances in eligible)\n",
    "    if total_capacity < deficit:\n",
    "        print(\n",
    "            f\"Peringatan: kapasitas augmentasi maksimum ({total_capacity}) lebih kecil dari kebutuhan ({deficit}). \"\n",
    "            \"Dataset mungkin tetap tidak seimbang.\"\n",
    "        )\n",
    "\n",
    "    idx = 0\n",
    "    iterations = 0\n",
    "    max_iterations = len(eligible) * max_aug_per_image if eligible else 0\n",
    "\n",
    "    while deficit > 0 and idx < max_iterations and eligible:\n",
    "        stem, instances = eligible[idx % len(eligible)]\n",
    "        if plan.get(stem, 0) >= max_aug_per_image:\n",
    "            idx += 1\n",
    "            iterations += 1\n",
    "            continue\n",
    "\n",
    "        plan[stem] = plan.get(stem, 0) + 1\n",
    "        deficit -= instances\n",
    "        idx += 1\n",
    "        iterations += 1\n",
    "\n",
    "    if deficit > 0:\n",
    "        print(f\"Peringatan: Masih ada selisih {deficit} instance setelah perencanaan augmentasi.\")\n",
    "\n",
    "    return plan\n",
    "\n",
    "# Mengambil patch objek dari polygon YOLO (segmentation)\n",
    "def extract_object_patch(image, polygon_coords, padding=2):\n",
    "    height, width = image.shape[:2]\n",
    "    if len(polygon_coords) < 6:\n",
    "        return None\n",
    "\n",
    "    pts = np.array(polygon_coords, dtype=np.float32).reshape(-1, 2)\n",
    "    x_px = np.clip(np.round(pts[:, 0] * width), 0, width - 1)\n",
    "    y_px = np.clip(np.round(pts[:, 1] * height), 0, height - 1)\n",
    "    pts_px = np.stack([x_px, y_px], axis=1).astype(np.int32)\n",
    "\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [pts_px], 1)\n",
    "\n",
    "    x_min = max(0, int(np.min(pts_px[:, 0])) - padding)\n",
    "    x_max = min(width, int(np.max(pts_px[:, 0])) + padding)\n",
    "    y_min = max(0, int(np.min(pts_px[:, 1])) - padding)\n",
    "    y_max = min(height, int(np.max(pts_px[:, 1])) + padding)\n",
    "\n",
    "    if x_max - x_min < 2 or y_max - y_min < 2:\n",
    "        return None\n",
    "\n",
    "    patch = image[y_min:y_max, x_min:x_max]\n",
    "    mask_patch = mask[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    if mask_patch.max() == 0:\n",
    "        return None\n",
    "\n",
    "    polygon_local = pts_px - np.array([x_min, y_min], dtype=np.int32)\n",
    "    return patch, mask_patch, polygon_local\n",
    "\n",
    "# Menempelkan patch pada gambar target dan mengembalikan polygon baru\n",
    "def paste_patch_on_base(base_image, patch, mask_patch, polygon_local, sigma=3):\n",
    "    base_height, base_width = base_image.shape[:2]\n",
    "    patch_height, patch_width = patch.shape[:2]\n",
    "\n",
    "    if patch_height == 0 or patch_width == 0:\n",
    "        return None\n",
    "\n",
    "    if patch_height > base_height or patch_width > base_width:\n",
    "        return None\n",
    "\n",
    "    max_x = base_width - patch_width\n",
    "    max_y = base_height - patch_height\n",
    "\n",
    "    if max_x < 0 or max_y < 0:\n",
    "        return None\n",
    "\n",
    "    if max_x == 0 and max_y == 0:\n",
    "        x_offset, y_offset = 0, 0\n",
    "    else:\n",
    "        x_offset = random.randint(0, max_x)\n",
    "        y_offset = random.randint(0, max_y)\n",
    "\n",
    "    mask_float = mask_patch.astype(np.float32)\n",
    "    if mask_float.max() == 0:\n",
    "        return None\n",
    "    mask_float /= mask_float.max()\n",
    "\n",
    "    if sigma and sigma > 0:\n",
    "        mask_float = cv2.GaussianBlur(mask_float, (0, 0), sigmaX=sigma, sigmaY=sigma)\n",
    "    mask_float = np.clip(mask_float, 0.0, 1.0)\n",
    "    mask_float = mask_float[..., None]\n",
    "\n",
    "    roi = base_image[y_offset:y_offset + patch_height, x_offset:x_offset + patch_width]\n",
    "    blended = (mask_float * patch.astype(np.float32) + (1.0 - mask_float) * roi.astype(np.float32)).astype(np.uint8)\n",
    "    base_image[y_offset:y_offset + patch_height, x_offset:x_offset + patch_width] = blended\n",
    "\n",
    "    polygon_shifted = polygon_local + np.array([x_offset, y_offset], dtype=np.int32)\n",
    "    polygon_norm = []\n",
    "    for x_px, y_px in polygon_shifted:\n",
    "        polygon_norm.append(float(np.clip(x_px / base_width, 0.0, 1.0)))\n",
    "        polygon_norm.append(float(np.clip(y_px / base_height, 0.0, 1.0)))\n",
    "\n",
    "    return polygon_norm\n",
    "\n",
    "print(\"Fungsi utilitas augmentasi copy-paste berhasil didefinisikan!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d9f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Konfigurasi path dan parameter copy-paste balancing\n",
    "from pathlib import Path\n",
    "\n",
    "# Gunakan path dataset dari hasil download Roboflow jika tersedia\n",
    "if 'dataset' in globals():\n",
    "    DATASET_PATH = Path(dataset.location).resolve()\n",
    "else:\n",
    "    DATASET_PATH = Path(f\"{HOME}/datasets/Rice-Grain-svjri-15\").resolve()\n",
    "\n",
    "DATA_CONFIG_PATH = (DATASET_PATH / \"data.yaml\").resolve()\n",
    "if not DATA_CONFIG_PATH.exists():\n",
    "    raise FileNotFoundError(f\"data.yaml tidak ditemukan di {DATA_CONFIG_PATH}. Pastikan dataset sudah diunduh.\")\n",
    "\n",
    "data_config = load_data_config(DATA_CONFIG_PATH, dataset_path_hint=DATASET_PATH)\n",
    "CLASS_NAMES = data_config[\"names\"]\n",
    "SPLITS = data_config[\"splits\"]\n",
    "\n",
    "if \"train\" not in SPLITS:\n",
    "    raise ValueError(\"Path train tidak ditemukan pada data.yaml. Pastikan konfigurasi dataset benar.\")\n",
    "\n",
    "TRAIN_IMAGES_PATH = SPLITS[\"train\"][\"images\"]\n",
    "TRAIN_LABELS_PATH = SPLITS[\"train\"][\"labels\"]\n",
    "VAL_IMAGES_PATH = SPLITS.get(\"val\", {}).get(\"images\")\n",
    "VAL_LABELS_PATH = SPLITS.get(\"val\", {}).get(\"labels\")\n",
    "TEST_IMAGES_PATH = SPLITS.get(\"test\", {}).get(\"images\")\n",
    "TEST_LABELS_PATH = SPLITS.get(\"test\", {}).get(\"labels\")\n",
    "\n",
    "# Verifikasi path yang dihasilkan\n",
    "for name, path_value in [\n",
    "    (\"TRAIN_IMAGES_PATH\", TRAIN_IMAGES_PATH),\n",
    "    (\"TRAIN_LABELS_PATH\", TRAIN_LABELS_PATH),\n",
    "    (\"VAL_IMAGES_PATH\", VAL_IMAGES_PATH),\n",
    "    (\"VAL_LABELS_PATH\", VAL_LABELS_PATH),\n",
    "    (\"TEST_IMAGES_PATH\", TEST_IMAGES_PATH),\n",
    "    (\"TEST_LABELS_PATH\", TEST_LABELS_PATH),\n",
    "]:\n",
    "    if path_value is None:\n",
    "        continue\n",
    "    if not path_value.exists():\n",
    "        print(f\"Peringatan: {name} tidak ditemukan di {path_value}\")\n",
    "\n",
    "# Parameter balancing berbasis copy-paste\n",
    "TARGET_MINORITY_CLASS_NAME = \"brown_spot\"\n",
    "DEFAULT_BASE_AUGMENTATIONS = 0      # augmentasi dasar untuk semua gambar\n",
    "MAX_AUG_PER_IMAGE = 5               # batas augmentasi tambahan per gambar minoritas\n",
    "COPY_PASTE_MIN_OBJECTS = 1          # minimal objek minoritas yang ditempel per gambar baru\n",
    "COPY_PASTE_MAX_OBJECTS = 3          # maksimal objek minoritas yang ditempel per gambar baru\n",
    "COPY_PASTE_PADDING = 4              # padding di sekitar mask saat memotong objek\n",
    "MASK_BLUR_SIGMA = 3                 # smoothing tepi saat penempelan\n",
    "APPLY_COLOR_AUG = False              # gunakan transformasi warna setelah copy-paste\n",
    "\n",
    "if COPY_PASTE_MAX_OBJECTS < COPY_PASTE_MIN_OBJECTS:\n",
    "    raise ValueError(\"COPY_PASTE_MAX_OBJECTS harus >= COPY_PASTE_MIN_OBJECTS\")\n",
    "\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "print(f\"Train images path: {TRAIN_IMAGES_PATH}\")\n",
    "print(f\"Train labels path: {TRAIN_LABELS_PATH}\")\n",
    "if VAL_IMAGES_PATH:\n",
    "    print(f\"Validation images path: {VAL_IMAGES_PATH}\")\n",
    "if TEST_IMAGES_PATH:\n",
    "    print(f\"Test images path: {TEST_IMAGES_PATH}\")\n",
    "print(f\"Jumlah kelas: {len(CLASS_NAMES)} -> {CLASS_NAMES}\")\n",
    "print(\"Parameter copy-paste:\")\n",
    "print(f\"  - Target kelas minoritas : {TARGET_MINORITY_CLASS_NAME}\")\n",
    "print(f\"  - Min objek per augmentasi: {COPY_PASTE_MIN_OBJECTS}\")\n",
    "print(f\"  - Max objek per augmentasi: {COPY_PASTE_MAX_OBJECTS}\")\n",
    "print(f\"  - Padding objek          : {COPY_PASTE_PADDING}\")\n",
    "print(f\"  - Mask blur sigma        : {MASK_BLUR_SIGMA}\")\n",
    "print(f\"  - Color augment aktif    : {APPLY_COLOR_AUG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17400eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analisis distribusi kelas & rencana balancing\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "train_counts, TRAIN_IMAGE_STATS = collect_class_stats(TRAIN_LABELS_PATH, NUM_CLASSES)\n",
    "val_counts = Counter({cls: 0 for cls in range(NUM_CLASSES)})\n",
    "test_counts = Counter({cls: 0 for cls in range(NUM_CLASSES)})\n",
    "\n",
    "if VAL_LABELS_PATH and VAL_LABELS_PATH.exists():\n",
    "    val_counts, _ = collect_class_stats(VAL_LABELS_PATH, NUM_CLASSES)\n",
    "if TEST_LABELS_PATH and TEST_LABELS_PATH.exists():\n",
    "    test_counts, _ = collect_class_stats(TEST_LABELS_PATH, NUM_CLASSES)\n",
    "\n",
    "print_class_distribution(\"Train (sebelum copy-paste)\", train_counts, CLASS_NAMES)\n",
    "if VAL_LABELS_PATH and VAL_LABELS_PATH.exists():\n",
    "    print_class_distribution(\"Validation\", val_counts, CLASS_NAMES)\n",
    "if TEST_LABELS_PATH and TEST_LABELS_PATH.exists():\n",
    "    print_class_distribution(\"Test\", test_counts, CLASS_NAMES)\n",
    "\n",
    "if TARGET_MINORITY_CLASS_NAME in CLASS_NAMES:\n",
    "    minority_class_id = CLASS_NAMES.index(TARGET_MINORITY_CLASS_NAME)\n",
    "else:\n",
    "    minority_class_id = min(train_counts, key=train_counts.get)\n",
    "majority_class_id = max(train_counts, key=train_counts.get)\n",
    "\n",
    "balance_deficit = train_counts[majority_class_id] - train_counts[minority_class_id]\n",
    "\n",
    "print(\"\\nRingkasan balancing:\")\n",
    "print(f\"Kelas mayoritas : {CLASS_NAMES[majority_class_id]} ({train_counts[majority_class_id]} instance)\")\n",
    "print(f\"Kelas minoritas : {CLASS_NAMES[minority_class_id]} ({train_counts[minority_class_id]} instance)\")\n",
    "print(f\"Selisih instance : {balance_deficit}\")\n",
    "\n",
    "AUGMENTATION_PLAN = build_balanced_augmentation_plan(\n",
    "    TRAIN_IMAGE_STATS,\n",
    "    target_class_id=minority_class_id,\n",
    "    deficit=balance_deficit,\n",
    "    max_aug_per_image=MAX_AUG_PER_IMAGE,\n",
    ")\n",
    "\n",
    "expected_new_minority = sum(\n",
    "    TRAIN_IMAGE_STATS[stem].get(minority_class_id, 0) * count\n",
    "    for stem, count in AUGMENTATION_PLAN.items()\n",
    ")\n",
    "\n",
    "print(f\"\\nRencana augmentasi untuk kelas {CLASS_NAMES[minority_class_id]}:\")\n",
    "print(f\"  - Jumlah gambar unik yang ditambah: {len(AUGMENTATION_PLAN)}\")\n",
    "print(f\"  - Total augmentasi baru: {sum(AUGMENTATION_PLAN.values())}\")\n",
    "print(f\"  - Perkiraan penambahan instance minoritas: {expected_new_minority}\")\n",
    "if balance_deficit > 0 and not AUGMENTATION_PLAN:\n",
    "    print(\"  ! Tidak ada gambar minoritas yang tersedia untuk di-augment. Dataset tetap tidak seimbang.\")\n",
    "\n",
    "BASELINE_TRAIN_COUNTS = train_counts.copy()\n",
    "MINORITY_CLASS_ID = minority_class_id\n",
    "MAJORITY_CLASS_ID = majority_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87305a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan augmentasi copy-paste pada segmentation dataset\n",
    "def augment_segmentation_dataset(\n",
    "    images_path,\n",
    "    labels_path,\n",
    "    base_num_augmentations=0,\n",
    "    augmentation_plan=None,\n",
    "    minority_class_id=0,\n",
    "    class_names=None,\n",
    "    apply_color_aug=False,\n",
    "    mask_blur_sigma=3,\n",
    "    min_objects_per_paste=1,\n",
    "    max_objects_per_paste=3,\n",
    "    padding=4,\n",
    "):\n",
    "    \"\"\"Generate balanced data using copy-paste augmentation for YOLO segmentation.\"\"\"\n",
    "\n",
    "    images_dir = Path(images_path)\n",
    "    labels_dir = Path(labels_path)\n",
    "    augmentation_plan = augmentation_plan or {}\n",
    "\n",
    "    image_files = sorted(list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.jpeg')) + list(images_dir.glob('*.png')))\n",
    "    if not image_files:\n",
    "        print(\"Tidak ada gambar ditemukan di direktori train.\")\n",
    "        return 0\n",
    "\n",
    "    stem_to_path = {img_path.stem: img_path for img_path in image_files}\n",
    "    label_exists = {stem: (labels_dir / f\"{stem}.txt\").exists() for stem in stem_to_path}\n",
    "    base_stems = [stem for stem, exists in label_exists.items() if exists]\n",
    "\n",
    "    if not base_stems:\n",
    "        print(\"Tidak ada file label YOLO yang ditemukan. Augmentasi dibatalkan.\")\n",
    "        return 0\n",
    "\n",
    "    class_names = class_names or []\n",
    "\n",
    "    augmented_images = 0\n",
    "    total_pasted_instances = 0\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    image_stems_to_process = [stem for stem in stem_to_path.keys() if base_num_augmentations + augmentation_plan.get(stem, 0) > 0]\n",
    "\n",
    "    for stem in tqdm(image_stems_to_process, desc=\"Applying Copy-Paste\"):\n",
    "        donor_img_path = stem_to_path[stem]\n",
    "        total_aug = base_num_augmentations + augmentation_plan.get(stem, 0)\n",
    "\n",
    "        donor_label_path = labels_dir / f\"{stem}.txt\"\n",
    "        if not donor_label_path.exists():\n",
    "            continue\n",
    "\n",
    "        donor_annotations = read_yolo_annotation(donor_label_path)\n",
    "        minority_annotations = [ann for ann in donor_annotations if int(ann[0]) == minority_class_id]\n",
    "        if not minority_annotations:\n",
    "            continue\n",
    "\n",
    "        donor_bgr = cv2.imread(str(donor_img_path))\n",
    "        if donor_bgr is None:\n",
    "            print(f\"Gagal membaca gambar donor: {donor_img_path}\")\n",
    "            continue\n",
    "        donor_rgb = cv2.cvtColor(donor_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        for aug_idx in range(total_aug):\n",
    "            base_stem = random.choice(base_stems)\n",
    "            base_img_path = stem_to_path[base_stem]\n",
    "            base_label_path = labels_dir / f\"{base_stem}.txt\"\n",
    "\n",
    "            base_annotations = read_yolo_annotation(base_label_path)\n",
    "            base_bgr = cv2.imread(str(base_img_path))\n",
    "            if base_bgr is None:\n",
    "                print(f\"Gagal membaca gambar target: {base_img_path}\")\n",
    "                continue\n",
    "            base_rgb = cv2.cvtColor(base_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            new_image = base_rgb.copy()\n",
    "            new_annotations = [list(ann) for ann in base_annotations]\n",
    "            pasted_this_image = 0\n",
    "\n",
    "            max_pick = min(max_objects_per_paste, len(minority_annotations))\n",
    "            min_pick = min(min_objects_per_paste, max_pick)\n",
    "            if max_pick <= 0 or min_pick <= 0:\n",
    "                continue\n",
    "\n",
    "            num_to_paste = random.randint(min_pick, max_pick)\n",
    "            selected_objects = random.sample(minority_annotations, num_to_paste)\n",
    "\n",
    "            for obj in selected_objects:\n",
    "                result = extract_object_patch(donor_rgb, obj[1:], padding=padding)\n",
    "                if result is None:\n",
    "                    continue\n",
    "                patch, mask_patch, polygon_local = result\n",
    "                new_polygon = paste_patch_on_base(\n",
    "                    new_image,\n",
    "                    patch,\n",
    "                    mask_patch,\n",
    "                    polygon_local,\n",
    "                    sigma=mask_blur_sigma,\n",
    "                )\n",
    "                if new_polygon is None:\n",
    "                    continue\n",
    "                new_annotations.append([obj[0]] + new_polygon)\n",
    "                pasted_this_image += 1\n",
    "                total_pasted_instances += 1\n",
    "\n",
    "            if pasted_this_image == 0:\n",
    "                continue\n",
    "\n",
    "            if apply_color_aug:\n",
    "                augmented = transform_color(image=new_image)\n",
    "                new_image = augmented['image']\n",
    "\n",
    "            base_suffix = base_img_path.suffix or '.jpg'\n",
    "            new_stem = f\"{base_stem}_cp_{stem}_{aug_idx}\"\n",
    "            unique_id = 0\n",
    "            new_image_path = images_dir / f\"{new_stem}{base_suffix}\"\n",
    "            new_label_path = labels_dir / f\"{new_stem}.txt\"\n",
    "\n",
    "            while new_image_path.exists() or new_label_path.exists():\n",
    "                unique_id += 1\n",
    "                new_stem = f\"{base_stem}_cp_{stem}_{aug_idx}_{unique_id}\"\n",
    "                new_image_path = images_dir / f\"{new_stem}{base_suffix}\"\n",
    "                new_label_path = labels_dir / f\"{new_stem}.txt\"\n",
    "\n",
    "            cv2.imwrite(str(new_image_path), cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR))\n",
    "            write_yolo_annotation(new_label_path, new_annotations)\n",
    "            augmented_images += 1\n",
    "\n",
    "    class_name = class_names[minority_class_id] if class_names and minority_class_id < len(class_names) else minority_class_id\n",
    "    print(\n",
    "        f\"\\nSelesai! Total {augmented_images} gambar baru telah dibuat dengan copy-paste.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Total instance kelas {class_name} yang ditempel: {total_pasted_instances}\"\n",
    "    )\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "print(\"Fungsi augment_segmentation_dataset copy-paste berhasil didefinisikan!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd7a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Jalankan augmentasi copy-paste\n",
    "print(\"Memulai proses augmentasi copy-paste dengan balancing kelas...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "augmented_count = augment_segmentation_dataset(\n",
    "    images_path=TRAIN_IMAGES_PATH,\n",
    "    labels_path=TRAIN_LABELS_PATH,\n",
    "    base_num_augmentations=DEFAULT_BASE_AUGMENTATIONS,\n",
    "    augmentation_plan=AUGMENTATION_PLAN,\n",
    "    minority_class_id=MINORITY_CLASS_ID,\n",
    "    class_names=CLASS_NAMES,\n",
    "    apply_color_aug=APPLY_COLOR_AUG,\n",
    "    mask_blur_sigma=MASK_BLUR_SIGMA,\n",
    "    min_objects_per_paste=COPY_PASTE_MIN_OBJECTS,\n",
    "    max_objects_per_paste=COPY_PASTE_MAX_OBJECTS,\n",
    "    padding=COPY_PASTE_PADDING,\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Augmentasi selesai!\")\n",
    "print(f\"Total gambar baru: {augmented_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704acb2",
   "metadata": {},
   "source": [
    "## Section 4: Final Verification and Visualization\n",
    "\n",
    "This section verifies the final state of the dataset after all augmentations (expansion and copy-paste) have been applied. It provides a final class distribution and visualizes a few samples to confirm the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27785d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verifikasi hasil augmentasi dan balancing\n",
    "train_counts_after, _ = collect_class_stats(TRAIN_LABELS_PATH, len(CLASS_NAMES))\n",
    "\n",
    "if VAL_LABELS_PATH and VAL_LABELS_PATH.exists():\n",
    "    val_counts_after, _ = collect_class_stats(VAL_LABELS_PATH, len(CLASS_NAMES))\n",
    "else:\n",
    "    val_counts_after = Counter({cls: 0 for cls in range(len(CLASS_NAMES))})\n",
    "\n",
    "if TEST_LABELS_PATH and TEST_LABELS_PATH.exists():\n",
    "    test_counts_after, _ = collect_class_stats(TEST_LABELS_PATH, len(CLASS_NAMES))\n",
    "else:\n",
    "    test_counts_after = Counter({cls: 0 for cls in range(len(CLASS_NAMES))})\n",
    "\n",
    "print(\"Statistik Dataset Setelah Semua Augmentasi Selesai:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Path dataset: {DATASET_PATH}\")\n",
    "print(f\"Train images path: {TRAIN_IMAGES_PATH}\")\n",
    "print(f\"Train labels path: {TRAIN_LABELS_PATH}\")\n",
    "\n",
    "if 'BASELINE_TRAIN_COUNTS' in globals():\n",
    "    print(\"\\nPerbandingan distribusi kelas (train):\")\n",
    "    for idx, class_name in enumerate(CLASS_NAMES):\n",
    "        before = BASELINE_TRAIN_COUNTS.get(idx, 0)\n",
    "        after = train_counts_after.get(idx, 0)\n",
    "        delta = after - before\n",
    "        sign = \"+\" if delta >= 0 else \"\"\n",
    "        print(f\"  - {class_name}: sebelum={before}, sesudah={after} ({sign}{delta})\")\n",
    "else:\n",
    "    print_class_distribution(\"Train (setelah augmentasi)\", train_counts_after, CLASS_NAMES)\n",
    "\n",
    "if VAL_LABELS_PATH and VAL_LABELS_PATH.exists():\n",
    "    print_class_distribution(\"Validation\", val_counts_after, CLASS_NAMES)\n",
    "if TEST_LABELS_PATH and TEST_LABELS_PATH.exists():\n",
    "    print_class_distribution(\"Test\", test_counts_after, CLASS_NAMES)\n",
    "\n",
    "print(\"\\nContoh file hasil augmentasi:\")\n",
    "aug_files = [\n",
    "    f for f in sorted(TRAIN_IMAGES_PATH.glob('*'))\n",
    "    if ('_aug' in f.stem or '_cp_' in f.stem) and f.suffix.lower() in {'.jpg', '.jpeg', '.png'}\n",
    "]\n",
    "for i, path in enumerate(random.sample(aug_files, min(5, len(aug_files)))):\n",
    "    print(f\"  {i+1}. {path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fc7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualisasi hasil augmentasi\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def visualize_augmentations(images_path, num_samples=4):\n",
    "    \"\"\"Visualisasi gambar original dan hasil augmentasinya.\"\"\"\n",
    "    images_dir = Path(images_path)\n",
    "    backup_dir = images_dir.parent / 'train_original_backup' / 'images'\n",
    "\n",
    "    if not backup_dir.exists():\n",
    "        print(f\"Direktori backup gambar original tidak ditemukan: {backup_dir}\")\n",
    "        return\n",
    "\n",
    "    original_images = list(backup_dir.glob('*.jpg')) + list(backup_dir.glob('*.png'))\n",
    "\n",
    "    if not original_images:\n",
    "        print(\"Tidak ada gambar original ditemukan di backup.\")\n",
    "        return\n",
    "\n",
    "    sample_images = random.sample(original_images, min(num_samples, len(original_images)))\n",
    "\n",
    "    for orig_path in sample_images:\n",
    "        base_name = orig_path.stem\n",
    "        aug_images = list(images_dir.glob(f'{base_name}_aug*.jpg')) + \\\n",
    "                     list(images_dir.glob(f'*_cp_{base_name}*.jpg'))\n",
    "\n",
    "        if not aug_images:\n",
    "            print(f\"Tidak ada hasil augmentasi ditemukan untuk {orig_path.name}.\")\n",
    "            continue\n",
    "            \n",
    "        num_cols = min(4, len(aug_images) + 1)\n",
    "        fig, axes = plt.subplots(1, num_cols, figsize=(20, 5))\n",
    "        if num_cols == 1: axes = [axes]\n",
    "\n",
    "        orig_img = Image.open(orig_path)\n",
    "        axes[0].imshow(orig_img)\n",
    "        axes[0].set_title('Original')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        for idx, aug_path in enumerate(random.sample(aug_images, min(num_cols - 1, len(aug_images)))):\n",
    "            aug_img = Image.open(aug_path)\n",
    "            axes[idx + 1].imshow(aug_img)\n",
    "            axes[idx + 1].set_title(aug_path.stem, fontsize=8)\n",
    "            axes[idx + 1].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(f\"Gambar: {orig_path.name}\")\n",
    "        print(f\"  - Ditemukan {len(aug_images)} augmentasi terkait.\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc89be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tampilkan visualisasi hasil augmentasi\n",
    "visualize_augmentations(TRAIN_IMAGES_PATH, num_samples=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

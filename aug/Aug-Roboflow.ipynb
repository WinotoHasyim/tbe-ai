{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eec6698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa919b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"ultralytics<=8.3.40\" supervision roboflow\n",
    "# prevent ultralytics from tracking your activity\n",
    "!yolo settings sync=False\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a34b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=yolo11m-seg.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "IPyImage(filename=f'{HOME}/runs/segment/predict/dog.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86266d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "model = YOLO('yolo11m-seg.pt')\n",
    "image = Image.open(requests.get('https://media.roboflow.com/notebooks/examples/dog.jpeg', stream=True).raw)\n",
    "result = model.predict(image, conf=0.25)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ba00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "!roboflow workspace list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {HOME}/datasets\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "from google.colab import userdata\n",
    "from roboflow import Roboflow\n",
    "\n",
    "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "\n",
    "workspace = rf.workspace(\"tbe\") # Your workspace ID\n",
    "project = workspace.project(\"rice-grain-svjri\") # Your project ID\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "\n",
    "!yolo task=segment mode=train model=yolo11m-seg.pt data={dataset.location}/data.yaml epochs=1000 imgsz=640 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {HOME}/runs/segment/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image as IPyImage\n",
    "\n",
    "# IPyImage(filename=f'{HOME}/runs/segment/train/confusion_matrix.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8bef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=segment mode=val model={HOME}/runs/segment/train/weights/best.pt data={dataset.location}/data.yaml imgsz=640 plots=True max_det=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d77c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "\n",
    "# Melakukan augmentasi pada dataset untuk meningkatkan variasi data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1384ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install library untuk augmentasi\n",
    "%pip install albumentations opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81798dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from collections import Counter\n",
    "\n",
    "# Fungsi untuk membaca annotation YOLO format\n",
    "def read_yolo_annotation(annotation_path):\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        annotations = []\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) > 0:\n",
    "                class_id = int(parts[0])\n",
    "                coords = [float(x) for x in parts[1:]]\n",
    "                annotations.append([class_id] + coords)\n",
    "    return annotations\n",
    "\n",
    "# Fungsi untuk menulis annotation YOLO format\n",
    "def write_yolo_annotation(annotation_path, annotations):\n",
    "    with open(annotation_path, 'w') as f:\n",
    "        for ann in annotations:\n",
    "            class_id = int(ann[0])\n",
    "            coords = ' '.join([f'{x:.6f}' for x in ann[1:]])\n",
    "            f.write(f'{class_id} {coords}\\n')\n",
    "\n",
    "# Fungsi untuk transformasi koordinat polygon\n",
    "def transform_polygon_coords(coords, img_width, img_height, transform_matrix):\n",
    "    \"\"\"Transform polygon coordinates using transformation matrix\"\"\"\n",
    "    transformed_coords = []\n",
    "    for i in range(0, len(coords), 2):\n",
    "        x = coords[i] * img_width\n",
    "        y = coords[i + 1] * img_height\n",
    "\n",
    "        # Apply transformation\n",
    "        if transform_matrix == 'horizontal_flip':\n",
    "            x = img_width - x\n",
    "        elif transform_matrix == 'vertical_flip':\n",
    "            y = img_height - y\n",
    "        elif transform_matrix == 'rotate_90':\n",
    "            x, y = img_height - y, x\n",
    "        elif transform_matrix == 'rotate_180':\n",
    "            x, y = img_width - x, img_height - y\n",
    "        elif transform_matrix == 'rotate_270':\n",
    "            x, y = y, img_width - x\n",
    "\n",
    "        # Normalize back\n",
    "        x_norm = x / img_width if transform_matrix not in ['rotate_90', 'rotate_270'] else x / img_height\n",
    "        y_norm = y / img_height if transform_matrix not in ['rotate_90', 'rotate_270'] else y / img_width\n",
    "\n",
    "        transformed_coords.extend([x_norm, y_norm])\n",
    "\n",
    "    return transformed_coords\n",
    "\n",
    "# Fungsi untuk apply transformasi individual dengan tracking\n",
    "def apply_tracked_transform(image, annotations, img_width, img_height):\n",
    "    \"\"\"Apply transformation dan track transformasi untuk koordinat\"\"\"\n",
    "    applied_transforms = []\n",
    "\n",
    "    # Apply HorizontalFlip\n",
    "    if np.random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        applied_transforms.append('horizontal_flip')\n",
    "\n",
    "    # Apply VerticalFlip\n",
    "    if np.random.random() < 0.5:\n",
    "        image = cv2.flip(image, 0)\n",
    "        applied_transforms.append('vertical_flip')\n",
    "\n",
    "    # Apply RandomRotate90\n",
    "    rotate_choice = np.random.random()\n",
    "    if rotate_choice < 0.5:\n",
    "        k = np.random.choice([1, 2, 3])  # 90, 180, or 270 degrees\n",
    "        image = np.rot90(image, k)\n",
    "        if k == 1:\n",
    "            applied_transforms.append('rotate_90')\n",
    "        elif k == 2:\n",
    "            applied_transforms.append('rotate_180')\n",
    "        elif k == 3:\n",
    "            applied_transforms.append('rotate_270')\n",
    "\n",
    "    transformed_annotations = []\n",
    "    for ann in annotations:\n",
    "        class_id = ann[0]\n",
    "        coords = ann[1:]\n",
    "\n",
    "        current_coords = coords\n",
    "        current_width = img_width\n",
    "        current_height = img_height\n",
    "\n",
    "        for transform_type in applied_transforms:\n",
    "            current_coords = transform_polygon_coords(\n",
    "                current_coords, current_width, current_height, transform_type\n",
    "            )\n",
    "            if transform_type in ['rotate_90', 'rotate_270']:\n",
    "                current_width, current_height = current_height, current_width\n",
    "\n",
    "        transformed_annotations.append([class_id] + current_coords)\n",
    "\n",
    "    return image, transformed_annotations\n",
    "\n",
    "# Fungsi untuk membaca konfigurasi dataset dari YAML\n",
    "def load_data_config(data_yaml_path):\n",
    "    data_yaml_path = Path(data_yaml_path)\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "\n",
    "    names = data.get('names', [])\n",
    "    if isinstance(names, dict):\n",
    "        names = [names[str(i)] for i in range(len(names))]\n",
    "\n",
    "    base_dir = data_yaml_path.parent\n",
    "\n",
    "    def resolve_path(path_value):\n",
    "        path_value = Path(path_value)\n",
    "        if not path_value.is_absolute():\n",
    "            return (base_dir / path_value).resolve()\n",
    "        return path_value.resolve()\n",
    "\n",
    "    splits = {}\n",
    "    for split_key in ('train', 'val', 'test'):\n",
    "        split_path = data.get(split_key)\n",
    "        if not split_path:\n",
    "            continue\n",
    "        images_dir = resolve_path(split_path)\n",
    "        labels_dir = (images_dir.parent / 'labels').resolve()\n",
    "        splits[split_key] = {\n",
    "            'images': images_dir,\n",
    "            'labels': labels_dir,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        'names': names,\n",
    "        'splits': splits,\n",
    "    }\n",
    "\n",
    "# Menghitung distribusi kelas dan statistik per gambar\n",
    "def collect_class_stats(labels_dir, num_classes):\n",
    "    labels_dir = Path(labels_dir)\n",
    "    counts = Counter({cls: 0 for cls in range(num_classes)})\n",
    "    image_stats = {}\n",
    "\n",
    "    for label_path in labels_dir.glob('*.txt'):\n",
    "        annotations = read_yolo_annotation(label_path)\n",
    "        per_image = Counter({cls: 0 for cls in range(num_classes)})\n",
    "        for ann in annotations:\n",
    "            class_id = int(ann[0])\n",
    "            if class_id >= num_classes:\n",
    "                continue\n",
    "            per_image[class_id] += 1\n",
    "            counts[class_id] += 1\n",
    "        image_stats[label_path.stem] = per_image\n",
    "\n",
    "    return counts, image_stats\n",
    "\n",
    "# Menampilkan distribusi kelas yang mudah dibaca\n",
    "def print_class_distribution(split_name, counts, class_names):\n",
    "    total = sum(counts.values())\n",
    "    print(f\"\\nDistribusi kelas untuk {split_name}:\")\n",
    "    for idx, class_name in enumerate(class_names):\n",
    "        value = counts.get(idx, 0)\n",
    "        if total > 0:\n",
    "            pct = (value / total) * 100\n",
    "            print(f\"  - {class_name}: {value} ({pct:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"  - {class_name}: {value}\")\n",
    "\n",
    "# Menentukan rencana augmentasi agar kelas minoritas mendekati jumlah kelas mayoritas\n",
    "def build_balanced_augmentation_plan(image_stats, target_class_id, deficit, max_aug_per_image=5):\n",
    "    plan = {}\n",
    "    if deficit <= 0:\n",
    "        return plan\n",
    "\n",
    "    eligible = []\n",
    "    for stem, stats in image_stats.items():\n",
    "        instances = stats.get(target_class_id, 0)\n",
    "        if instances > 0:\n",
    "            eligible.append((stem, instances))\n",
    "\n",
    "    if not eligible:\n",
    "        return plan\n",
    "\n",
    "    eligible.sort(key=lambda item: item[1], reverse=True)\n",
    "    total_capacity = sum(instances * max_aug_per_image for _, instances in eligible)\n",
    "    if total_capacity < deficit:\n",
    "        print(\n",
    "            f\"Peringatan: kapasitas augmentasi maksimum ({total_capacity}) lebih kecil dari kebutuhan ({deficit}). \"\n",
    "            \"Dataset mungkin tetap tidak seimbang.\"\n",
    "        )\n",
    "\n",
    "    idx = 0\n",
    "    iterations = 0\n",
    "    max_iterations = len(eligible) * max_aug_per_image if eligible else 0\n",
    "\n",
    "    while deficit > 0 and idx < max_iterations and eligible:\n",
    "        stem, instances = eligible[idx % len(eligible)]\n",
    "        if plan.get(stem, 0) >= max_aug_per_image:\n",
    "            idx += 1\n",
    "            iterations += 1\n",
    "            continue\n",
    "\n",
    "        plan[stem] = plan.get(stem, 0) + 1\n",
    "        deficit -= instances\n",
    "        idx += 1\n",
    "        iterations += 1\n",
    "\n",
    "    if deficit > 0:\n",
    "        print(f\"Peringatan: Masih ada selisih {deficit} instance setelah perencanaan augmentasi.\")\n",
    "\n",
    "    return plan\n",
    "\n",
    "print(\"Fungsi utilitas augmentasi dan analisis dataset berhasil didefinisikan!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisi pipeline augmentasi\n",
    "# Transformasi geometri (flip, rotate) ditangani secara manual\n",
    "# Albumentations hanya untuk transformasi pixel/color yang tidak ubah koordinat\n",
    "import albumentations as A\n",
    "\n",
    "transform_color = A.Compose([\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=0.2, \n",
    "        contrast_limit=0.2, \n",
    "        p=0.5\n",
    "    ),\n",
    "    A.HueSaturationValue(\n",
    "        hue_shift_limit=10,\n",
    "        sat_shift_limit=20,\n",
    "        val_shift_limit=10,\n",
    "        p=0.5\n",
    "    ),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "    A.CLAHE(clip_limit=2.0, p=0.3),\n",
    "], bbox_params=None)\n",
    "\n",
    "print(\"Pipeline augmentasi berhasil didefinisikan!\")\n",
    "print(\"\\nTeknik augmentasi yang digunakan:\")\n",
    "print(\"Transformasi Geometri (dengan transformasi koordinat):\")\n",
    "print(\"  1. HorizontalFlip (50%)\")\n",
    "print(\"  2. VerticalFlip (50%)\")\n",
    "print(\"  3. RandomRotate90 (50%)\")\n",
    "print(\"\\nTransformasi Warna/Pixel:\")\n",
    "print(\"  4. RandomBrightnessContrast (50%)\")\n",
    "print(\"  5. HueSaturationValue (50%)\")\n",
    "print(\"  6. GaussNoise (30%)\")\n",
    "print(\"  7. GaussianBlur (30%)\")\n",
    "print(\"  8. CLAHE (30%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fc7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi hasil augmentasi\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def visualize_augmentations(images_path, num_samples=4):\n",
    "    \"\"\"Visualisasi gambar original dan hasil augmentasinya\"\"\"\n",
    "    images_dir = Path(images_path)\n",
    "    \n",
    "    # Dapatkan gambar original (bukan hasil augmentasi)\n",
    "    original_images = [f for f in os.listdir(images_path) if '_aug' not in f and f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if len(original_images) == 0:\n",
    "        print(\"Tidak ada gambar original ditemukan\")\n",
    "        return\n",
    "    \n",
    "    # Pilih beberapa gambar secara random\n",
    "    sample_images = random.sample(original_images, min(num_samples, len(original_images)))\n",
    "    \n",
    "    for orig_name in sample_images:\n",
    "        # Cari semua augmentasi dari gambar ini\n",
    "        base_name = Path(orig_name).stem\n",
    "        aug_images = [f for f in os.listdir(images_path) if f.startswith(base_name + '_aug')]\n",
    "        \n",
    "        # Siapkan plot\n",
    "        num_cols = min(4, len(aug_images) + 1)\n",
    "        fig, axes = plt.subplots(1, num_cols, figsize=(20, 5))\n",
    "        \n",
    "        if num_cols == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        # Tampilkan gambar original\n",
    "        orig_img = Image.open(os.path.join(images_path, orig_name))\n",
    "        axes[0].imshow(orig_img)\n",
    "        axes[0].set_title('Original')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Tampilkan gambar hasil augmentasi\n",
    "        for idx, aug_name in enumerate(aug_images[:num_cols-1]):\n",
    "            aug_img = Image.open(os.path.join(images_path, aug_name))\n",
    "            axes[idx+1].imshow(aug_img)\n",
    "            axes[idx+1].set_title(f'Augmented {idx+1}')\n",
    "            axes[idx+1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(f\"Gambar: {orig_name}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# NOTE: the actual call to visualize_augmentations is moved later to after augmentation run/verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfigurasi path dan parameter balancing\n",
    "from pathlib import Path\n",
    "\n",
    "# Gunakan path dataset dari hasil download Roboflow jika tersedia\n",
    "if 'dataset' in globals():\n",
    "    DATASET_PATH = Path(dataset.location)\n",
    "else:\n",
    "    DATASET_PATH = Path(\"/content/datasets/Rice-Grain-4\")\n",
    "\n",
    "DATA_CONFIG_PATH = DATASET_PATH / \"data.yaml\"\n",
    "data_config = load_data_config(DATA_CONFIG_PATH)\n",
    "CLASS_NAMES = data_config[\"names\"]\n",
    "SPLITS = data_config[\"splits\"]\n",
    "\n",
    "if \"train\" not in SPLITS:\n",
    "    raise ValueError(\"Path train tidak ditemukan pada data.yaml. Pastikan konfigurasi dataset benar.\")\n",
    "\n",
    "TRAIN_IMAGES_PATH = SPLITS[\"train\"][\"images\"]\n",
    "TRAIN_LABELS_PATH = SPLITS[\"train\"][\"labels\"]\n",
    "VAL_IMAGES_PATH = SPLITS.get(\"val\", {}).get(\"images\")\n",
    "VAL_LABELS_PATH = SPLITS.get(\"val\", {}).get(\"labels\")\n",
    "TEST_IMAGES_PATH = SPLITS.get(\"test\", {}).get(\"images\")\n",
    "TEST_LABELS_PATH = SPLITS.get(\"test\", {}).get(\"labels\")\n",
    "\n",
    "# Parameter balancing\n",
    "TARGET_MINORITY_CLASS_NAME = \"brown_spot\"\n",
    "DEFAULT_BASE_AUGMENTATIONS = 0  # augmentasi default untuk semua gambar\n",
    "MAX_AUG_PER_IMAGE = 5           # batas augmentasi tambahan per gambar minoritas\n",
    "\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "print(f\"Train images path: {TRAIN_IMAGES_PATH}\")\n",
    "print(f\"Train labels path: {TRAIN_LABELS_PATH}\")\n",
    "if VAL_IMAGES_PATH:\n",
    "    print(f\"Validation images path: {VAL_IMAGES_PATH}\")\n",
    "if TEST_IMAGES_PATH:\n",
    "    print(f\"Test images path: {TEST_IMAGES_PATH}\")\n",
    "print(f\"Jumlah kelas: {len(CLASS_NAMES)} -> {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17400eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis distribusi kelas & rencana balancing\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "train_counts, TRAIN_IMAGE_STATS = collect_class_stats(TRAIN_LABELS_PATH, NUM_CLASSES)\n",
    "val_counts = Counter({cls: 0 for cls in range(NUM_CLASSES)})\n",
    "test_counts = Counter({cls: 0 for cls in range(NUM_CLASSES)})\n",
    "\n",
    "if VAL_LABELS_PATH:\n",
    "    val_counts, _ = collect_class_stats(VAL_LABELS_PATH, NUM_CLASSES)\n",
    "if TEST_LABELS_PATH:\n",
    "    test_counts, _ = collect_class_stats(TEST_LABELS_PATH, NUM_CLASSES)\n",
    "\n",
    "print_class_distribution(\"Train (sebelum augmentasi)\", train_counts, CLASS_NAMES)\n",
    "if VAL_LABELS_PATH:\n",
    "    print_class_distribution(\"Validation\", val_counts, CLASS_NAMES)\n",
    "if TEST_LABELS_PATH:\n",
    "    print_class_distribution(\"Test\", test_counts, CLASS_NAMES)\n",
    "\n",
    "if TARGET_MINORITY_CLASS_NAME in CLASS_NAMES:\n",
    "    minority_class_id = CLASS_NAMES.index(TARGET_MINORITY_CLASS_NAME)\n",
    "else:\n",
    "    minority_class_id = min(train_counts, key=train_counts.get)\n",
    "majority_class_id = max(train_counts, key=train_counts.get)\n",
    "\n",
    "balance_deficit = train_counts[majority_class_id] - train_counts[minority_class_id]\n",
    "\n",
    "print(\"\\nRingkasan balancing:\")\n",
    "print(f\"Kelas mayoritas : {CLASS_NAMES[majority_class_id]} ({train_counts[majority_class_id]} instance)\")\n",
    "print(f\"Kelas minoritas : {CLASS_NAMES[minority_class_id]} ({train_counts[minority_class_id]} instance)\")\n",
    "print(f\"Selisih instance : {balance_deficit}\")\n",
    "\n",
    "AUGMENTATION_PLAN = build_balanced_augmentation_plan(\n",
    "    TRAIN_IMAGE_STATS,\n",
    "    target_class_id=minority_class_id,\n",
    "    deficit=balance_deficit,\n",
    "    max_aug_per_image=MAX_AUG_PER_IMAGE,\n",
    ")\n",
    "\n",
    "expected_new_minority = sum(\n",
    "    TRAIN_IMAGE_STATS[stem].get(minority_class_id, 0) * count\n",
    "    for stem, count in AUGMENTATION_PLAN.items()\n",
    ")\n",
    "\n",
    "print(f\"\\nRencana augmentasi untuk kelas {CLASS_NAMES[minority_class_id]}:\")\n",
    "print(f\"  - Jumlah gambar unik yang ditambah: {len(AUGMENTATION_PLAN)}\")\n",
    "print(f\"  - Total augmentasi baru: {sum(AUGMENTATION_PLAN.values())}\")\n",
    "print(f\"  - Perkiraan penambahan instance minoritas: {expected_new_minority}\")\n",
    "if balance_deficit > 0 and not AUGMENTATION_PLAN:\n",
    "    print(\"  ! Tidak ada gambar minoritas yang tersedia untuk di-augment. Dataset tetap tidak seimbang.\")\n",
    "\n",
    "BASELINE_TRAIN_COUNTS = train_counts.copy()\n",
    "MINORITY_CLASS_ID = minority_class_id\n",
    "MAJORITY_CLASS_ID = majority_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87305a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan augmentasi pada segmentation dataset\n",
    "def augment_segmentation_dataset(\n",
    "    images_path,\n",
    "    labels_path,\n",
    "    base_num_augmentations=0,\n",
    "    augmentation_plan=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Augmentasi dataset dengan format YOLO segmentation secara class-aware.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images_path : str | Path\n",
    "        Direktori gambar.\n",
    "    labels_path : str | Path\n",
    "        Direktori label (YOLO segmentation).\n",
    "    base_num_augmentations : int, default 0\n",
    "        Jumlah augmentasi dasar untuk setiap gambar (dapat 0 jika hanya pakai augmentation_plan).\n",
    "    augmentation_plan : dict[str, int], optional\n",
    "        Mapping nama file (tanpa ekstensi) -> jumlah augmentasi tambahan untuk balancing kelas.\n",
    "    \"\"\"\n",
    "    images_dir = Path(images_path)\n",
    "    labels_dir = Path(labels_path)\n",
    "    augmentation_plan = augmentation_plan or {}\n",
    "\n",
    "    image_files = sorted(list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.jpeg')) + list(images_dir.glob('*.png')))\n",
    "\n",
    "    print(f\"Ditemukan {len(image_files)} gambar untuk evaluasi augmentasi\")\n",
    "\n",
    "    augmented_count = 0\n",
    "\n",
    "    for img_path in tqdm(image_files, desc=\"Augmentasi gambar\"):\n",
    "        image = cv2.imread(str(img_path))\n",
    "        if image is None:\n",
    "            print(f\"Gagal membaca gambar: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        img_height, img_width = image.shape[:2]\n",
    "\n",
    "        label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
    "        if not label_path.exists():\n",
    "            print(f\"Tidak ada label untuk: {img_path.name}\")\n",
    "            continue\n",
    "\n",
    "        annotations = read_yolo_annotation(label_path)\n",
    "        if len(annotations) == 0:\n",
    "            continue\n",
    "\n",
    "        planned_augmentations = augmentation_plan.get(img_path.stem, base_num_augmentations)\n",
    "        if planned_augmentations <= 0:\n",
    "            continue\n",
    "\n",
    "        next_aug_index = 0\n",
    "        while (images_dir / f\"{img_path.stem}_aug{next_aug_index}{img_path.suffix}\").exists() or \\\n",
    "                (labels_dir / f\"{img_path.stem}_aug{next_aug_index}.txt\").exists():\n",
    "            next_aug_index += 1\n",
    "\n",
    "        for aug_round in range(planned_augmentations):\n",
    "            augmented_image, transformed_annotations = apply_tracked_transform(\n",
    "                image.copy(), annotations, img_width, img_height\n",
    "            )\n",
    "\n",
    "            color_transformed = transform_color(image=augmented_image)\n",
    "            augmented_image = color_transformed['image']\n",
    "\n",
    "            current_index = next_aug_index + aug_round\n",
    "            aug_img_name = f\"{img_path.stem}_aug{current_index}{img_path.suffix}\"\n",
    "            aug_img_path = images_dir / aug_img_name\n",
    "\n",
    "            augmented_image_bgr = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(str(aug_img_path), augmented_image_bgr)\n",
    "\n",
    "            aug_label_name = f\"{img_path.stem}_aug{current_index}.txt\"\n",
    "            aug_label_path = labels_dir / aug_label_name\n",
    "            write_yolo_annotation(aug_label_path, transformed_annotations)\n",
    "\n",
    "            augmented_count += 1\n",
    "\n",
    "    print(f\"\\nSelesai! Total {augmented_count} gambar baru telah dibuat\")\n",
    "    print(f\"Dataset sekarang memiliki {len(image_files) + augmented_count} gambar training\")\n",
    "\n",
    "    return augmented_count\n",
    "\n",
    "print(\"Fungsi augment_segmentation_dataset (class-aware) berhasil didefinisikan!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jalankan augmentasi\n",
    "print(\"Memulai proses augmentasi dengan balancing kelas...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "augmented_count = augment_segmentation_dataset(\n",
    "    images_path=TRAIN_IMAGES_PATH,\n",
    "    labels_path=TRAIN_LABELS_PATH,\n",
    "    base_num_augmentations=DEFAULT_BASE_AUGMENTATIONS,\n",
    "    augmentation_plan=AUGMENTATION_PLAN,\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Augmentasi selesai!\")\n",
    "print(f\"Total gambar baru: {augmented_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27785d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifikasi hasil augmentasi dan balancing\n",
    "train_counts_after, _ = collect_class_stats(TRAIN_LABELS_PATH, len(CLASS_NAMES))\n",
    "\n",
    "if VAL_LABELS_PATH:\n",
    "    val_counts_after, _ = collect_class_stats(VAL_LABELS_PATH, len(CLASS_NAMES))\n",
    "else:\n",
    "    val_counts_after = Counter({cls: 0 for cls in range(len(CLASS_NAMES))})\n",
    "\n",
    "if TEST_LABELS_PATH:\n",
    "    test_counts_after, _ = collect_class_stats(TEST_LABELS_PATH, len(CLASS_NAMES))\n",
    "else:\n",
    "    test_counts_after = Counter({cls: 0 for cls in range(len(CLASS_NAMES))})\n",
    "\n",
    "print(\"Statistik Dataset Setelah Augmentasi:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Path dataset: {DATASET_PATH}\")\n",
    "print(f\"Train images path: {TRAIN_IMAGES_PATH}\")\n",
    "print(f\"Train labels path: {TRAIN_LABELS_PATH}\")\n",
    "\n",
    "if 'BASELINE_TRAIN_COUNTS' in globals():\n",
    "    print(\"\\nPerbandingan distribusi kelas (train):\")\n",
    "    for idx, class_name in enumerate(CLASS_NAMES):\n",
    "        before = BASELINE_TRAIN_COUNTS.get(idx, 0)\n",
    "        after = train_counts_after.get(idx, 0)\n",
    "        delta = after - before\n",
    "        sign = \"+\" if delta >= 0 else \"\"\n",
    "        print(f\"  - {class_name}: sebelum={before}, sesudah={after} ({sign}{delta})\")\n",
    "else:\n",
    "    print_class_distribution(\"Train (setelah augmentasi)\", train_counts_after, CLASS_NAMES)\n",
    "\n",
    "if VAL_LABELS_PATH:\n",
    "    print_class_distribution(\"Validation\", val_counts_after, CLASS_NAMES)\n",
    "if TEST_LABELS_PATH:\n",
    "    print_class_distribution(\"Test\", test_counts_after, CLASS_NAMES)\n",
    "\n",
    "print(\"\\nContoh file hasil augmentasi:\")\n",
    "aug_files = [\n",
    "    f for f in sorted(TRAIN_IMAGES_PATH.glob('*'))\n",
    "    if '_aug' in f.stem and f.suffix.lower() in {'.jpg', '.jpeg', '.png'}\n",
    "]\n",
    "for i, path in enumerate(aug_files[:5]):\n",
    "    print(f\"  {i+1}. {path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc89be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan visualisasi hasil augmentasi\n",
    "visualize_augmentations(TRAIN_IMAGES_PATH, num_samples=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_lab1 (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

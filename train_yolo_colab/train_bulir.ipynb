{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe9vkEvFABbN"
      },
      "source": [
        "[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
        "\n",
        "# How to Train YOLO11 Instance Segmentation on a Custom Dataset\n",
        "\n",
        "---\n",
        "\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ultralytics/ultralytics)\n",
        "\n",
        "YOLO11 builds on the advancements introduced in YOLOv9 and YOLOv10 earlier this year, incorporating improved architectural designs, enhanced feature extraction techniques, and optimized training methods.\n",
        "\n",
        "YOLO11m achieves a higher mean mAP score on the COCO dataset while using 22% fewer parameters than YOLOv8m, making it computationally lighter without sacrificing performance.\n",
        "\n",
        "YOLOv11 is available in 5 different sizes, ranging from `2.6M` to `56.9M` parameters, and capable of achieving from `39.5` to `54.7` mAP on the COCO dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO4jp3hX8dhj"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfvTJ0-ejc33"
      },
      "source": [
        "### Configure API keys\n",
        "\n",
        "To fine-tune YOLO11, you need to provide your Roboflow API key. Follow these steps:\n",
        "\n",
        "- Go to your [`Roboflow Settings`](https://app.roboflow.com/settings/api) page. Click `Copy`. This will place your private key in the clipboard.\n",
        "- In Colab, go to the left pane and click on `Secrets` (🔑). Store Roboflow API Key under the name `ROBOFLOW_API_KEY`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "### Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Catat waktu mulai\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "p_GFSMk7Q0z0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "ba9fed40-eb74-4049-fab4-8c842cb84cdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcvTRlHH8n5V"
      },
      "source": [
        "**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "d291bd39-6bd9-49c3-f869-86995e30ca10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1h-Ppqf6wRPv",
        "outputId": "f0125807-4073-43d8-b6ff-09878f0742f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RUNS_FOLDER_NAME = \"TBE_runs_bulir\""
      ],
      "metadata": {
        "id": "XUUDubtmQZR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir = f\"/content/drive/MyDrive/{RUNS_FOLDER_NAME}\"\n",
        "os.makedirs(dst_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "uYaf-dNxwTA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "## Install YOLO11 via Ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdSMcABDNKW-"
      },
      "outputs": [],
      "source": [
        "%pip install ultralytics supervision roboflow\n",
        "# prevent ultralytics from tracking your activity\n",
        "!yolo settings sync=False\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSI-qYxsG6Wl"
      },
      "source": [
        "## Fine-tune YOLO11 on custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGOP0bCgH4cb"
      },
      "source": [
        "**NOTE:** When training YOLOv11, make sure your data is located in `datasets`. If you'd like to change the default location of the data you want to use for fine-tuning, you can do so through Ultralytics' `settings.json`. In this tutorial, we will use one of the [datasets](https://universe.roboflow.com/ks-fsm9o/pelvis-ap-x-ray) available on [Roboflow Universe](https://universe.roboflow.com/). When downloading, make sure to select the `yolov11` export format."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "!roboflow workspace list"
      ],
      "metadata": {
        "id": "L59RJ1bRagX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSd93ZJzZZKt"
      },
      "outputs": [],
      "source": [
        "!mkdir -p {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# --- IMPORTANT: SET YOUR ROBOFLOW CREDENTIALS ---\n",
        "# Option 1: If using Google Colab, use userdata secrets.\n",
        "from google.colab import userdata\n",
        "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "VERSION = 21 # Dataset version in roboflow\n",
        "\n",
        "# Option 2: Paste your API key directly (less secure).\n",
        "# ROBOFLOW_API_KEY = \"YOUR_ROBOFLOW_API_KEY\" # <-- PASTE YOUR KEY HERE\n",
        "\n",
        "if ROBOFLOW_API_KEY == \"YOUR_ROBOFLOW_API_KEY\":\n",
        "    print(\"ERROR: Please replace 'YOUR_ROBOFLOW_API_KEY' with your actual Roboflow API key.\")\n",
        "else:\n",
        "    rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "    workspace = rf.workspace(\"tbe\") # Your workspace ID\n",
        "    project = workspace.project(\"rice-grain-svjri\") # Your project ID\n",
        "    version = project.version(VERSION)\n",
        "    dataset = version.download(\"yolov11\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bulir Padi Segmentation: Advanced Augmentation Pipeline\n",
        "\n",
        "This notebook extends the original Roboflow data loading and copy-paste augmentation with a more advanced, offline augmentation pipeline. The key additions are:\n",
        "\n",
        "1.  **Conditional Tiling**: High-resolution images are tiled to handle large inputs effectively.\n",
        "2.  **Randomized Augmentations**: A variety of geometric, color, and structural augmentations are applied randomly to increase dataset variance.\n",
        "3.  **Dataset Expansion**: The training set is expanded by a configurable factor (e.g., 5x).\n",
        "4.  **Detailed Logging**: The process generates a summary of augmentations and class distributions.\n",
        "\n",
        "The original copy-paste logic for class balancing is preserved and will run *after* this new pipeline has expanded the dataset."
      ],
      "metadata": {
        "id": "mgVPYajVC7an"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Pre-Augmentation Setup & Utilities\n",
        "\n",
        "This section contains all the necessary imports, configurations, and helper functions for the new augmentation pipeline."
      ],
      "metadata": {
        "id": "IdouefpLC9vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library for augmentation\n",
        "%pip install albumentations opencv-python-headless scikit-image"
      ],
      "metadata": {
        "id": "StKKip-qC-6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Imports for Tiling, Augmentation, and Logging\n",
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from tqdm.notebook import tqdm\n",
        "import yaml\n",
        "from collections import Counter, defaultdict\n",
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "from skimage.measure import find_contours\n",
        "\n",
        "# --- Configuration for New Augmentation Pipeline ---\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# 1. Preprocessing - Conditional Tiling\n",
        "TILING_THRESHOLD = 1500  # Tile images with width or height > 1500px\n",
        "TILE_SIZE = (1024, 1024)   # Size of each tile\n",
        "TILE_OVERLAP = 0.1       # 10% overlap between tiles\n",
        "\n",
        "# 2. Dataset Expansion\n",
        "EXPANSION_FACTOR = 5  # Target: 5x the original dataset size\n",
        "\n",
        "# 3. Randomized Augmentation Logic\n",
        "NUM_AUGMENTATIONS_MIN = 3 # Min number of augmentations to apply per image\n",
        "NUM_AUGMENTATIONS_MAX = 5 # Max number of augmentations to apply per image\n",
        "\n",
        "print(\"Configuration for Tiling and Augmentation pipeline is set.\")"
      ],
      "metadata": {
        "id": "inQzNQMpDAyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Functions for Mask and Annotation Conversion ---\n",
        "\n",
        "def yolo_to_masks(annotation_path, img_height, img_width):\n",
        "    \"\"\"Reads YOLO segmentation format and converts it to a list of binary masks.\"\"\"\n",
        "    masks = []\n",
        "    class_ids = []\n",
        "    if not Path(annotation_path).exists():\n",
        "        return masks, class_ids\n",
        "\n",
        "    with open(annotation_path, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) > 1:\n",
        "                class_id = int(parts[0])\n",
        "                poly = np.array(parts[1:], dtype=np.float32).reshape(-1, 2)\n",
        "                poly[:, 0] *= img_width\n",
        "                poly[:, 1] *= img_height\n",
        "                poly = poly.astype(np.int32)\n",
        "\n",
        "                mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
        "                cv2.fillPoly(mask, [poly], 1)\n",
        "                masks.append(mask)\n",
        "                class_ids.append(class_id)\n",
        "    return masks, class_ids\n",
        "\n",
        "def masks_to_yolo(masks, class_ids, img_height, img_width):\n",
        "    \"\"\"Converts a list of binary masks back to YOLO segmentation format.\"\"\"\n",
        "    annotations = []\n",
        "    for i, mask in enumerate(masks):\n",
        "        if np.sum(mask) == 0:\n",
        "            continue\n",
        "        # Pad mask to avoid issues at edges\n",
        "        padded_mask = np.pad(mask, pad_width=1, mode='constant', constant_values=0)\n",
        "        contours = find_contours(padded_mask, 0.5)\n",
        "\n",
        "        if not contours:\n",
        "            continue\n",
        "        # Use the largest contour\n",
        "        contour = max(contours, key=len)\n",
        "        # Revert padding effect\n",
        "        contour -= 1\n",
        "\n",
        "        # YOLO format requires x, y coordinates\n",
        "        # find_contours returns y, x, so we flip them\n",
        "        contour = np.flip(contour, axis=1)\n",
        "\n",
        "        if len(contour) < 3:\n",
        "            continue\n",
        "\n",
        "        # Normalize\n",
        "        contour = contour.astype(np.float32)\n",
        "        contour[:, 0] /= img_width\n",
        "        contour[:, 1] /= img_height\n",
        "\n",
        "        contour = np.clip(contour, 0.0, 1.0)\n",
        "\n",
        "        yolo_coords = ' '.join([f'{coord:.6f}' for coord in contour.flatten()])\n",
        "        annotations.append(f\"{int(class_ids[i])} {yolo_coords}\")\n",
        "    return annotations\n",
        "\n",
        "print(\"Mask and YOLO annotation conversion utilities are defined.\")"
      ],
      "metadata": {
        "id": "imMgpnJXDB_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Core Preprocessing and Augmentation Functions ---\n",
        "\n",
        "def tile_if_highres(image, masks):\n",
        "    \"\"\"Performs tiling only on high-resolution images.\"\"\"\n",
        "    height, width = image.shape[:2]\n",
        "    if width <= TILING_THRESHOLD and height <= TILING_THRESHOLD:\n",
        "        return [(image, masks)], False  # Return original as a single-item list\n",
        "\n",
        "    tiled_data = []\n",
        "    tile_w, tile_h = TILE_SIZE\n",
        "    step_w = int(tile_w * (1 - TILE_OVERLAP))\n",
        "    step_h = int(tile_h * (1 - TILE_OVERLAP))\n",
        "\n",
        "    for y in range(0, height, step_h):\n",
        "        for x in range(0, width, step_w):\n",
        "            x1, y1 = x, y\n",
        "            x2, y2 = min(x + tile_w, width), min(y + tile_h, height)\n",
        "\n",
        "            # Skip tiles that are too small\n",
        "            if (x2 - x1) < tile_w / 2 or (y2 - y1) < tile_h / 2:\n",
        "                continue\n",
        "\n",
        "            tile_img = image[y1:y2, x1:x2]\n",
        "            tile_masks = [m[y1:y2, x1:x2] for m in masks]\n",
        "\n",
        "            # Only keep tiles that contain at least part of an object\n",
        "            if any(np.sum(m) > 0 for m in tile_masks):\n",
        "                tiled_data.append((tile_img, tile_masks))\n",
        "\n",
        "    return tiled_data, True\n",
        "\n",
        "def get_augmentation_pipelines():\n",
        "    \"\"\"Defines augmentation pipelines in the order: geometric → affine → structural → color → noise_blur\"\"\"\n",
        "\n",
        "    pipelines = {\n",
        "        # Resizing / Cropping (always applied first, not counted in random selection)\n",
        "        'cropping': A.Compose([\n",
        "            A.SmallestMaxSize(max_size=TILE_SIZE[0], p=1.0),\n",
        "            A.RandomResizedCrop(\n",
        "                size=(TILE_SIZE[0], TILE_SIZE[1]),\n",
        "                scale=(0.6, 1.0),          # crop area relative to original\n",
        "                ratio=(0.75, 1.3333),      # aspect ratio range (width/height)\n",
        "                interpolation=1,            # cv2.INTER_LINEAR\n",
        "                p=1.0\n",
        "            )\n",
        "        ], p=1.0, seed=SEED),\n",
        "\n",
        "        # Step 1: Geometric\n",
        "        'geometric': A.Compose([\n",
        "            A.HorizontalFlip(p=1.0),\n",
        "            A.VerticalFlip(p=1.0),\n",
        "            A.RandomRotate90(p=1.0)\n",
        "        ], p=1.0, seed=SEED),\n",
        "\n",
        "        # Step 2: Affine / Perspective\n",
        "        'affine': A.Compose([\n",
        "            A.ShiftScaleRotate(\n",
        "                shift_limit=0.15, scale_limit=0.2, rotate_limit=20, p=1.0\n",
        "            ),\n",
        "            A.Affine(shear=(-10, 10), p=1.0),\n",
        "            A.Perspective(scale=(0.05, 0.15), keep_size=True, p=1.0)\n",
        "        ], p=1.0, seed=SEED),\n",
        "\n",
        "        # Step 3: Dropout / occlusion\n",
        "        'structural': A.Compose([\n",
        "            A.CoarseDropout(\n",
        "                num_holes_range=(1, 8),\n",
        "                hole_height_range=(0.02, 0.1),\n",
        "                hole_width_range=(0.02, 0.1),\n",
        "                fill=0,\n",
        "                fill_mask=None,\n",
        "                p=1.0\n",
        "            ),\n",
        "            A.GridDistortion(p=1.0),\n",
        "        ], p=1.0, seed=SEED),\n",
        "\n",
        "        # Step 4: Color\n",
        "        'color': A.Compose([\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
        "            A.HueSaturationValue(hue_shift_limit=0, sat_shift_limit=30, val_shift_limit=20, p=1.0),\n",
        "            A.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=1.0),\n",
        "        ], p=1.0, seed=SEED),\n",
        "\n",
        "        # Step 5: Noise / Blur\n",
        "        'noise_blur': A.Compose([\n",
        "            A.GaussNoise(std_range=(0.04, 0.2), mean_range=(0.0, 0.0), per_channel=True, noise_scale_factor=1.0, p=1.0),\n",
        "            A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
        "            A.ISONoise(p=1.0)\n",
        "        ], p=1.0, seed=SEED),\n",
        "    }\n",
        "\n",
        "    return pipelines\n",
        "\n",
        "def apply_random_augmentations(image, masks, pipelines):\n",
        "    \"\"\"\n",
        "    Applies resizing/cropping first, then randomly selects 3-5 categories from the step_order.\n",
        "    For each selected category, only one transform from that category is applied.\n",
        "    \"\"\"\n",
        "    # --- Always apply resizing / cropping first ---\n",
        "    cropped = pipelines['cropping'](image=image, masks=masks)\n",
        "    augmented_image = cropped['image']\n",
        "    augmented_masks = cropped['masks']\n",
        "\n",
        "    # Step order\n",
        "    step_order = ['geometric', 'affine', 'structural', 'color', 'noise_blur']\n",
        "\n",
        "    # Randomly pick 3-5 categories\n",
        "    num_to_apply = random.randint(NUM_AUGMENTATIONS_MIN, NUM_AUGMENTATIONS_MAX)\n",
        "    chosen_categories = random.sample(step_order, num_to_apply)\n",
        "\n",
        "    applied_augs = []\n",
        "\n",
        "    # Apply each chosen category in step_order\n",
        "    for category in step_order:\n",
        "        if category in chosen_categories:\n",
        "            transforms = pipelines[category].transforms\n",
        "            if transforms:\n",
        "                # Randomly pick ONE transform from the category\n",
        "                transform_to_apply = random.choice(transforms)\n",
        "                temp_pipeline = A.Compose([transform_to_apply])\n",
        "                transformed = temp_pipeline(image=augmented_image, masks=augmented_masks)\n",
        "                augmented_image = transformed['image']\n",
        "                augmented_masks = transformed['masks']\n",
        "                applied_augs.append(transform_to_apply.__class__.__name__)\n",
        "\n",
        "    return augmented_image, augmented_masks, applied_augs\n",
        "\n",
        "print(\"Core preprocessing and augmentation functions are defined.\")"
      ],
      "metadata": {
        "id": "MjobQ2RPDDKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Logging and Summary Function ---\n",
        "\n",
        "def log_augmentation_stats(stats, output_dir):\n",
        "    \"\"\"Generates and saves a summary of the augmentation process.\"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    summary = {}\n",
        "\n",
        "    # 1. Dataset Size\n",
        "    summary['Dataset Size'] = {\n",
        "        'Before': stats['initial_image_count'],\n",
        "        'After': stats['final_image_count']\n",
        "    }\n",
        "\n",
        "    # 2. Per-class Counts\n",
        "    class_names = stats['class_names']\n",
        "    summary['Class Counts Before'] = {class_names[i]: count for i, count in stats['initial_class_counts'].items()}\n",
        "    summary['Class Counts After'] = {class_names[i]: count for i, count in stats['final_class_counts'].items()}\n",
        "\n",
        "    # 3. Augmentation Frequency\n",
        "    total_augs = sum(stats['augmentation_freq'].values())\n",
        "    summary['Augmentation Frequency'] = {\n",
        "        aug: {\n",
        "            'Count': count,\n",
        "            'Percentage': f\"{(count / total_augs * 100):.2f}%\" if total_augs > 0 else \"0.00%\"\n",
        "        } for aug, count in sorted(stats['augmentation_freq'].items())\n",
        "    }\n",
        "    summary['Tiling Info'] = {\n",
        "        'Images Tiled': stats['tiling_info']['images_tiled'],\n",
        "        'Total Tiles Generated': stats['tiling_info']['tiles_generated']\n",
        "    }\n",
        "\n",
        "    # --- Print Summary Table ---\n",
        "    print(\"\\n--- Augmentation Summary ---\")\n",
        "    print(f\"Dataset Size: {summary['Dataset Size']['Before']} -> {summary['Dataset Size']['After']}\")\n",
        "\n",
        "    df_classes = pd.DataFrame([\n",
        "        summary['Class Counts Before'],\n",
        "        summary['Class Counts After']\n",
        "    ], index=['Before', 'After']).T\n",
        "    print(\"\\nClass Distribution:\")\n",
        "    print(df_classes.to_string())\n",
        "\n",
        "    df_augs = pd.DataFrame.from_dict(summary['Augmentation Frequency'], orient='index')\n",
        "    print(\"\\nAugmentation Frequency:\")\n",
        "    print(df_augs.to_string())\n",
        "\n",
        "    print(f\"\\nImages Tiled: {summary['Tiling Info']['Images Tiled']}\")\n",
        "    print(f\"Total Tiles Generated: {summary['Tiling Info']['Total Tiles Generated']}\")\n",
        "\n",
        "    # --- Save to CSV ---\n",
        "    csv_path = output_dir / 'augmentation_summary.csv'\n",
        "    try:\n",
        "        df_summary = pd.concat([df_classes.T, df_augs.T]).T\n",
        "        df_summary.to_csv(csv_path)\n",
        "        print(f\"\\nSummary saved to {csv_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nCould not save summary CSV: {e}\")\n",
        "\n",
        "    return summary\n",
        "\n",
        "print(\"Logging and summary function is defined.\")"
      ],
      "metadata": {
        "id": "uGO7T86iDEV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Main Augmentation Pipeline Execution\n",
        "\n",
        "This is the main execution block. It performs the following steps:\n",
        "1.  Backs up the original training data.\n",
        "2.  Calculates the target number of images for expansion.\n",
        "3.  Iterates through the original dataset, applying tiling and random augmentations.\n",
        "4.  Saves the newly generated images, masks, and metadata to a temporary directory.\n",
        "5.  Overwrites the original training data with the augmented data.\n",
        "6.  Logs the final statistics.\n",
        "\n",
        "**Note:** This process will modify your dataset in place. The backup is created in `train_original_backup`."
      ],
      "metadata": {
        "id": "aXScsUSYDFm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset paths from Roboflow download\n",
        "if 'dataset' in globals():\n",
        "    DATASET_PATH = Path(dataset.location).resolve()\n",
        "else:\n",
        "    # Fallback if the Roboflow cell was skipped\n",
        "    DATASET_PATH = Path(f\"{HOME}/datasets/Rice-Grain-svjri-{VERSION}\").resolve()\n",
        "    print(f\"WARNING: Roboflow 'dataset' object not found. Using fallback path: {DATASET_PATH}\")\n",
        "\n",
        "DATA_CONFIG_PATH = DATASET_PATH / \"data.yaml\"\n",
        "if not DATA_CONFIG_PATH.exists():\n",
        "    raise FileNotFoundError(f\"data.yaml not found at {DATA_CONFIG_PATH}. Please ensure the dataset was downloaded correctly.\")\n",
        "\n",
        "# Load data config\n",
        "with open(DATA_CONFIG_PATH, 'r') as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "CLASS_NAMES = data_config['names']\n",
        "\n",
        "TRAIN_IMAGES_PATH = DATASET_PATH / data_config['train'].replace(\"../\", \"\")\n",
        "TRAIN_LABELS_PATH = TRAIN_IMAGES_PATH.parent / 'labels'\n",
        "\n",
        "print(f\"Dataset Location: {DATASET_PATH}\")\n",
        "print(f\"Train Images Path: {TRAIN_IMAGES_PATH}\")\n",
        "print(f\"Train Labels Path: {TRAIN_LABELS_PATH}\")\n",
        "print(f\"Class Names: {CLASS_NAMES}\")"
      ],
      "metadata": {
        "id": "c-o7Bk2WDG2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Execution Block ---\n",
        "print(\"Starting the advanced augmentation and dataset expansion process...\")\n",
        "\n",
        "# 1. Backup original data\n",
        "original_images_path = TRAIN_IMAGES_PATH\n",
        "original_labels_path = TRAIN_LABELS_PATH\n",
        "backup_images_path = DATASET_PATH / 'train_original_backup' / 'images'\n",
        "backup_labels_path = DATASET_PATH / 'train_original_backup' / 'labels'\n",
        "\n",
        "if not backup_images_path.exists() and original_images_path.exists():\n",
        "    print(\"Backing up original training data...\")\n",
        "    shutil.copytree(original_images_path, backup_images_path)\n",
        "    shutil.copytree(original_labels_path, backup_labels_path)\n",
        "    print(f\"Backup complete in {DATASET_PATH / 'train_original_backup'}\")\n",
        "else:\n",
        "    print(\"Backup already exists or source is missing. Using existing backup as source.\")\n",
        "    original_images_path = backup_images_path\n",
        "    original_labels_path = backup_labels_path\n",
        "\n",
        "# 2. Prepare temporary directory for augmented data\n",
        "temp_aug_images_path = DATASET_PATH / 'train_augmented_temp' / 'images'\n",
        "temp_aug_labels_path = DATASET_PATH / 'train_augmented_temp' / 'labels'\n",
        "shutil.rmtree(temp_aug_images_path.parent, ignore_errors=True)\n",
        "temp_aug_images_path.mkdir(parents=True, exist_ok=True)\n",
        "temp_aug_labels_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 3. Initialize stats and pipelines\n",
        "image_files = sorted(list(original_images_path.glob('*.jpg')) + list(original_images_path.glob('*.png')))\n",
        "initial_image_count = len(image_files)\n",
        "target_image_count = initial_image_count * EXPANSION_FACTOR\n",
        "\n",
        "stats = {\n",
        "    'initial_image_count': initial_image_count,\n",
        "    'final_image_count': 0,\n",
        "    'class_names': CLASS_NAMES,\n",
        "    'initial_class_counts': Counter(),\n",
        "    'final_class_counts': Counter(),\n",
        "    'augmentation_freq': Counter(),\n",
        "    'tiling_info': {'images_tiled': 0, 'tiles_generated': 0}\n",
        "}\n",
        "pipelines = get_augmentation_pipelines()\n",
        "\n",
        "# 4. Main Augmentation Loop\n",
        "pbar = tqdm(total=target_image_count, desc=\"Generating Augmented Data\")\n",
        "generated_count = 0\n",
        "\n",
        "# First pass: collect initial stats\n",
        "for img_path in image_files:\n",
        "    label_path = original_labels_path / f\"{img_path.stem}.txt\"\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            stats['initial_class_counts'][int(line.split()[0])] += 1\n",
        "    # Also copy original files to the new location\n",
        "    shutil.copy(img_path, temp_aug_images_path)\n",
        "    shutil.copy(label_path, temp_aug_labels_path)\n",
        "    generated_count += 1\n",
        "    pbar.update(1)\n",
        "\n",
        "# Second pass: generate new augmented images until target is reached\n",
        "while generated_count < target_image_count:\n",
        "    img_path = random.choice(image_files)\n",
        "    label_path = original_labels_path / f\"{img_path.stem}.txt\"\n",
        "\n",
        "    image = cv2.imread(str(img_path))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    masks, class_ids = yolo_to_masks(label_path, height, width)\n",
        "    if not masks:\n",
        "        continue\n",
        "\n",
        "    # Step 1: Conditional Tiling\n",
        "    tiled_data, was_tiled = tile_if_highres(image, masks)\n",
        "    if was_tiled:\n",
        "        stats['tiling_info']['images_tiled'] += 1\n",
        "        stats['tiling_info']['tiles_generated'] += len(tiled_data)\n",
        "\n",
        "    # Process each tile (or the original image if not tiled)\n",
        "    for i, (tile_img, tile_masks) in enumerate(tiled_data):\n",
        "        if generated_count >= target_image_count: break\n",
        "\n",
        "        # Step 2: Random Augmentations\n",
        "        aug_img, aug_masks, applied_augs = apply_random_augmentations(tile_img, tile_masks, pipelines)\n",
        "\n",
        "        # Update stats\n",
        "        for aug_name in applied_augs:\n",
        "            stats['augmentation_freq'][aug_name] += 1\n",
        "\n",
        "        # Step 3: Save augmented data\n",
        "        new_stem = f\"{img_path.stem}_aug_{generated_count}\"\n",
        "        if was_tiled: new_stem += f\"_tile_{i}\"\n",
        "\n",
        "        new_img_path = temp_aug_images_path / f\"{new_stem}.jpg\"\n",
        "        new_label_path = temp_aug_labels_path / f\"{new_stem}.txt\"\n",
        "        new_meta_path = temp_aug_labels_path / f\"{new_stem}.json\"\n",
        "\n",
        "        aug_height, aug_width = aug_img.shape[:2]\n",
        "        yolo_annotations = masks_to_yolo(aug_masks, class_ids, aug_height, aug_width)\n",
        "\n",
        "        if yolo_annotations:\n",
        "            cv2.imwrite(str(new_img_path), cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
        "            with open(new_label_path, 'w') as f:\n",
        "                f.write('\\n'.join(yolo_annotations))\n",
        "\n",
        "            metadata = {\n",
        "                'original_image': img_path.name,\n",
        "                'tiling_applied': was_tiled,\n",
        "                'applied_augmentations': applied_augs\n",
        "            }\n",
        "            with open(new_meta_path, 'w') as f:\n",
        "                json.dump(metadata, f, indent=4)\n",
        "\n",
        "            generated_count += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "pbar.close()\n",
        "\n",
        "# 5. Overwrite original data with augmented data\n",
        "print(\"\\nReplacing original training data with augmented version...\")\n",
        "shutil.rmtree(TRAIN_IMAGES_PATH)\n",
        "shutil.rmtree(TRAIN_LABELS_PATH)\n",
        "shutil.move(str(temp_aug_images_path), str(TRAIN_IMAGES_PATH))\n",
        "shutil.move(str(temp_aug_labels_path), str(TRAIN_LABELS_PATH))\n",
        "shutil.rmtree(temp_aug_images_path.parent) # Clean up temp parent folder\n",
        "print(\"Dataset overwrite complete.\")\n",
        "\n",
        "# 6. Final Stats Calculation and Logging\n",
        "final_image_files = list(TRAIN_IMAGES_PATH.glob('*.jpg'))\n",
        "stats['final_image_count'] = len(final_image_files)\n",
        "for label_file in TRAIN_LABELS_PATH.glob('*.txt'):\n",
        "    with open(label_file, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            stats['final_class_counts'][int(line.split()[0])] += 1\n",
        "\n",
        "log_augmentation_stats(stats, DATASET_PATH)"
      ],
      "metadata": {
        "id": "3_EITK5wDJ41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Section 3: Original Copy-Paste Augmentation for Class Balancing\n",
        "\n",
        "The following cells contain the **original, untouched** copy-paste augmentation logic. This code will now run on the newly expanded and augmented dataset created in the previous section.\n",
        "\n",
        "Its purpose is to perform a final balancing pass, specifically targeting the minority class by copying its instances onto other images.\n",
        "---"
      ],
      "metadata": {
        "id": "SkP9neQwDLMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "# Fungsi untuk membaca annotation YOLO format\n",
        "def read_yolo_annotation(annotation_path):\n",
        "    with open(annotation_path, 'r') as f:\n",
        "        annotations = []\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) > 0:\n",
        "                class_id = int(parts[0])\n",
        "                coords = [float(x) for x in parts[1:]]\n",
        "                annotations.append([class_id] + coords)\n",
        "    return annotations\n",
        "\n",
        "# Fungsi untuk menulis annotation YOLO format\n",
        "def write_yolo_annotation(annotation_path, annotations):\n",
        "    with open(annotation_path, 'w') as f:\n",
        "        for ann in annotations:\n",
        "            class_id = int(ann[0])\n",
        "            coords = ' '.join([f'{x:.6f}' for x in ann[1:]])\n",
        "            f.write(f'{class_id} {coords}\\n')\n",
        "\n",
        "# Fungsi untuk membaca konfigurasi dataset dari YAML\n",
        "def load_data_config(data_yaml_path, dataset_path_hint=None):\n",
        "    data_yaml_path = Path(data_yaml_path)\n",
        "    with open(data_yaml_path, 'r') as f:\n",
        "        data = yaml.safe_load(f)\n",
        "\n",
        "    names = data.get('names', [])\n",
        "    if isinstance(names, dict):\n",
        "        names = [names[str(i)] for i in range(len(names))]\n",
        "\n",
        "    if dataset_path_hint:\n",
        "        base_dir = Path(dataset_path_hint).resolve()\n",
        "    else:\n",
        "        base_dir = data_yaml_path.parent.resolve()\n",
        "\n",
        "    def resolve_path(path_value: str | Path):\n",
        "        path_value = Path(path_value)\n",
        "        if path_value.is_absolute():\n",
        "            return path_value.resolve()\n",
        "        parts = []\n",
        "        for part in path_value.parts:\n",
        "            if part == '..':\n",
        "                if parts:\n",
        "                    parts.pop()\n",
        "            elif part != '.':\n",
        "                parts.append(part)\n",
        "        normalized = Path(*parts) if parts else Path('.')\n",
        "        resolved = (base_dir / normalized).resolve()\n",
        "        return resolved\n",
        "\n",
        "    splits = {}\n",
        "    for split_key in ('train', 'val', 'test'):\n",
        "        split_path = data.get(split_key)\n",
        "        if not split_path:\n",
        "            continue\n",
        "        images_dir = resolve_path(split_path)\n",
        "        labels_dir = (images_dir.parent / 'labels').resolve()\n",
        "        splits[split_key] = {\n",
        "            'images': images_dir,\n",
        "            'labels': labels_dir,\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        'names': names,\n",
        "        'splits': splits,\n",
        "    }\n",
        "\n",
        "# Menghitung distribusi kelas dan statistik per gambar\n",
        "def collect_class_stats(labels_dir, num_classes):\n",
        "    labels_dir = Path(labels_dir)\n",
        "    counts = Counter({cls: 0 for cls in range(num_classes)})\n",
        "    image_stats = {}\n",
        "\n",
        "    for label_path in labels_dir.glob('*.txt'):\n",
        "        annotations = read_yolo_annotation(label_path)\n",
        "        per_image = Counter({cls: 0 for cls in range(num_classes)})\n",
        "        for ann in annotations:\n",
        "            class_id = int(ann[0])\n",
        "            if class_id >= num_classes:\n",
        "                continue\n",
        "            per_image[class_id] += 1\n",
        "            counts[class_id] += 1\n",
        "        image_stats[label_path.stem] = per_image\n",
        "\n",
        "    return counts, image_stats\n",
        "\n",
        "# Menampilkan distribusi kelas yang mudah dibaca\n",
        "def print_class_distribution(split_name, counts, class_names):\n",
        "    total = sum(counts.values())\n",
        "    print(f\"\\nDistribusi kelas untuk {split_name}:\")\n",
        "    for idx, class_name in enumerate(class_names):\n",
        "        value = counts.get(idx, 0)\n",
        "        if total > 0:\n",
        "            pct = (value / total) * 100\n",
        "            print(f\"  - {class_name}: {value} ({pct:.2f}%)\")\n",
        "        else:\n",
        "            print(f\"  - {class_name}: {value}\")\n",
        "\n",
        "# Menentukan rencana augmentasi agar kelas minoritas mendekati jumlah kelas mayoritas\n",
        "def build_balanced_augmentation_plan(image_stats, target_class_id, deficit, max_aug_per_image=5):\n",
        "    plan = {}\n",
        "    if deficit <= 0:\n",
        "        return plan\n",
        "\n",
        "    eligible = []\n",
        "    for stem, stats in image_stats.items():\n",
        "        instances = stats.get(target_class_id, 0)\n",
        "        if instances > 0:\n",
        "            eligible.append((stem, instances))\n",
        "\n",
        "    if not eligible:\n",
        "        return plan\n",
        "\n",
        "    eligible.sort(key=lambda item: item[1], reverse=True)\n",
        "    total_capacity = sum(instances * max_aug_per_image for _, instances in eligible)\n",
        "    if total_capacity < deficit:\n",
        "        print(\n",
        "            f\"Peringatan: kapasitas augmentasi maksimum ({total_capacity}) lebih kecil dari kebutuhan ({deficit}). \"\n",
        "            \"Dataset mungkin tetap tidak seimbang.\"\n",
        "        )\n",
        "\n",
        "    idx = 0\n",
        "    iterations = 0\n",
        "    max_iterations = len(eligible) * max_aug_per_image if eligible else 0\n",
        "\n",
        "    while deficit > 0 and idx < max_iterations and eligible:\n",
        "        stem, instances = eligible[idx % len(eligible)]\n",
        "        if plan.get(stem, 0) >= max_aug_per_image:\n",
        "            idx += 1\n",
        "            iterations += 1\n",
        "            continue\n",
        "\n",
        "        plan[stem] = plan.get(stem, 0) + 1\n",
        "        deficit -= instances\n",
        "        idx += 1\n",
        "        iterations += 1\n",
        "\n",
        "    if deficit > 0:\n",
        "        print(f\"Peringatan: Masih ada selisih {deficit} instance setelah perencanaan augmentasi.\")\n",
        "\n",
        "    return plan\n",
        "\n",
        "# Mengambil patch objek dari polygon YOLO (segmentation)\n",
        "def extract_object_patch(image, polygon_coords, padding=2):\n",
        "    height, width = image.shape[:2]\n",
        "    if len(polygon_coords) < 6:\n",
        "        return None\n",
        "\n",
        "    pts = np.array(polygon_coords, dtype=np.float32).reshape(-1, 2)\n",
        "    x_px = np.clip(np.round(pts[:, 0] * width), 0, width - 1)\n",
        "    y_px = np.clip(np.round(pts[:, 1] * height), 0, height - 1)\n",
        "    pts_px = np.stack([x_px, y_px], axis=1).astype(np.int32)\n",
        "\n",
        "    mask = np.zeros((height, width), dtype=np.uint8)\n",
        "    cv2.fillPoly(mask, [pts_px], 1)\n",
        "\n",
        "    x_min = max(0, int(np.min(pts_px[:, 0])) - padding)\n",
        "    x_max = min(width, int(np.max(pts_px[:, 0])) + padding)\n",
        "    y_min = max(0, int(np.min(pts_px[:, 1])) - padding)\n",
        "    y_max = min(height, int(np.max(pts_px[:, 1])) + padding)\n",
        "\n",
        "    if x_max - x_min < 2 or y_max - y_min < 2:\n",
        "        return None\n",
        "\n",
        "    patch = image[y_min:y_max, x_min:x_max]\n",
        "    mask_patch = mask[y_min:y_max, x_min:x_max]\n",
        "\n",
        "    if mask_patch.max() == 0:\n",
        "        return None\n",
        "\n",
        "    polygon_local = pts_px - np.array([x_min, y_min], dtype=np.int32)\n",
        "    return patch, mask_patch, polygon_local\n",
        "\n",
        "# Menempelkan patch pada gambar target dan mengembalikan polygon baru\n",
        "def paste_patch_on_base(base_image, patch, mask_patch, polygon_local, sigma=3):\n",
        "    base_height, base_width = base_image.shape[:2]\n",
        "    patch_height, patch_width = patch.shape[:2]\n",
        "\n",
        "    if patch_height == 0 or patch_width == 0:\n",
        "        return None\n",
        "\n",
        "    if patch_height > base_height or patch_width > base_width:\n",
        "        return None\n",
        "\n",
        "    max_x = base_width - patch_width\n",
        "    max_y = base_height - patch_height\n",
        "\n",
        "    if max_x < 0 or max_y < 0:\n",
        "        return None\n",
        "\n",
        "    if max_x == 0 and max_y == 0:\n",
        "        x_offset, y_offset = 0, 0\n",
        "    else:\n",
        "        x_offset = random.randint(0, max_x)\n",
        "        y_offset = random.randint(0, max_y)\n",
        "\n",
        "    mask_float = mask_patch.astype(np.float32)\n",
        "    if mask_float.max() == 0:\n",
        "        return None\n",
        "    mask_float /= mask_float.max()\n",
        "\n",
        "    if sigma and sigma > 0:\n",
        "        mask_float = cv2.GaussianBlur(mask_float, (0, 0), sigmaX=sigma, sigmaY=sigma)\n",
        "    mask_float = np.clip(mask_float, 0.0, 1.0)\n",
        "    mask_float = mask_float[..., None]\n",
        "\n",
        "    roi = base_image[y_offset:y_offset + patch_height, x_offset:x_offset + patch_width]\n",
        "    blended = (mask_float * patch.astype(np.float32) + (1.0 - mask_float) * roi.astype(np.float32)).astype(np.uint8)\n",
        "    base_image[y_offset:y_offset + patch_height, x_offset:x_offset + patch_width] = blended\n",
        "\n",
        "    polygon_shifted = polygon_local + np.array([x_offset, y_offset], dtype=np.int32)\n",
        "    polygon_norm = []\n",
        "    for x_px, y_px in polygon_shifted:\n",
        "        polygon_norm.append(float(np.clip(x_px / base_width, 0.0, 1.0)))\n",
        "        polygon_norm.append(float(np.clip(y_px / base_height, 0.0, 1.0)))\n",
        "\n",
        "    return polygon_norm\n",
        "\n",
        "print(\"Fungsi utilitas augmentasi copy-paste berhasil didefinisikan!\")"
      ],
      "metadata": {
        "id": "gSoCf6YMDRfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konfigurasi path dan parameter copy-paste balancing\n",
        "from pathlib import Path\n",
        "\n",
        "# Gunakan path dataset dari hasil download Roboflow jika tersedia\n",
        "if 'dataset' in globals():\n",
        "    DATASET_PATH = Path(dataset.location).resolve()\n",
        "else:\n",
        "    DATASET_PATH = Path(f\"{HOME}/datasets/Rice-Grain-svjri-{VERSION}\").resolve()\n",
        "\n",
        "DATA_CONFIG_PATH = (DATASET_PATH / \"data.yaml\").resolve()\n",
        "if not DATA_CONFIG_PATH.exists():\n",
        "    raise FileNotFoundError(f\"data.yaml tidak ditemukan di {DATA_CONFIG_PATH}. Pastikan dataset sudah diunduh.\")\n",
        "\n",
        "data_config = load_data_config(DATA_CONFIG_PATH, dataset_path_hint=DATASET_PATH)\n",
        "CLASS_NAMES = data_config[\"names\"]\n",
        "SPLITS = data_config[\"splits\"]\n",
        "\n",
        "if \"train\" not in SPLITS:\n",
        "    raise ValueError(\"Path train tidak ditemukan pada data.yaml. Pastikan konfigurasi dataset benar.\")\n",
        "\n",
        "TRAIN_IMAGES_PATH = SPLITS[\"train\"][\"images\"]\n",
        "TRAIN_LABELS_PATH = SPLITS[\"train\"][\"labels\"]\n",
        "VAL_IMAGES_PATH = SPLITS.get(\"val\", {}).get(\"images\")\n",
        "VAL_LABELS_PATH = SPLITS.get(\"val\", {}).get(\"labels\")\n",
        "TEST_IMAGES_PATH = SPLITS.get(\"test\", {}).get(\"images\")\n",
        "TEST_LABELS_PATH = SPLITS.get(\"test\", {}).get(\"labels\")\n",
        "\n",
        "# Verifikasi path yang dihasilkan\n",
        "for name, path_value in [\n",
        "    (\"TRAIN_IMAGES_PATH\", TRAIN_IMAGES_PATH),\n",
        "    (\"TRAIN_LABELS_PATH\", TRAIN_LABELS_PATH),\n",
        "    (\"VAL_IMAGES_PATH\", VAL_IMAGES_PATH),\n",
        "    (\"VAL_LABELS_PATH\", VAL_LABELS_PATH),\n",
        "    (\"TEST_IMAGES_PATH\", TEST_IMAGES_PATH),\n",
        "    (\"TEST_LABELS_PATH\", TEST_LABELS_PATH),\n",
        "]:\n",
        "    if path_value is None:\n",
        "        continue\n",
        "    if not path_value.exists():\n",
        "        print(f\"Peringatan: {name} tidak ditemukan di {path_value}\")\n",
        "\n",
        "# Parameter balancing berbasis copy-paste\n",
        "TARGET_MINORITY_CLASS_NAME = \"brown_spot\"\n",
        "DEFAULT_BASE_AUGMENTATIONS = 0      # augmentasi dasar untuk semua gambar\n",
        "MAX_AUG_PER_IMAGE = 5               # batas augmentasi tambahan per gambar minoritas\n",
        "COPY_PASTE_MIN_OBJECTS = 1          # minimal objek minoritas yang ditempel per gambar baru\n",
        "COPY_PASTE_MAX_OBJECTS = 3          # maksimal objek minoritas yang ditempel per gambar baru\n",
        "COPY_PASTE_PADDING = 4              # padding di sekitar mask saat memotong objek\n",
        "MASK_BLUR_SIGMA = 3                 # smoothing tepi saat penempelan\n",
        "APPLY_COLOR_AUG = False              # gunakan transformasi warna setelah copy-paste\n",
        "\n",
        "if COPY_PASTE_MAX_OBJECTS < COPY_PASTE_MIN_OBJECTS:\n",
        "    raise ValueError(\"COPY_PASTE_MAX_OBJECTS harus >= COPY_PASTE_MIN_OBJECTS\")\n",
        "\n",
        "print(f\"Dataset path: {DATASET_PATH}\")\n",
        "print(f\"Train images path: {TRAIN_IMAGES_PATH}\")\n",
        "print(f\"Train labels path: {TRAIN_LABELS_PATH}\")\n",
        "if VAL_IMAGES_PATH:\n",
        "    print(f\"Validation images path: {VAL_IMAGES_PATH}\")\n",
        "if TEST_IMAGES_PATH:\n",
        "    print(f\"Test images path: {TEST_IMAGES_PATH}\")\n",
        "print(f\"Jumlah kelas: {len(CLASS_NAMES)} -> {CLASS_NAMES}\")\n",
        "print(\"Parameter copy-paste:\")\n",
        "print(f\"  - Target kelas minoritas : {TARGET_MINORITY_CLASS_NAME}\")\n",
        "print(f\"  - Min objek per augmentasi: {COPY_PASTE_MIN_OBJECTS}\")\n",
        "print(f\"  - Max objek per augmentasi: {COPY_PASTE_MAX_OBJECTS}\")\n",
        "print(f\"  - Padding objek          : {COPY_PASTE_PADDING}\")\n",
        "print(f\"  - Mask blur sigma        : {MASK_BLUR_SIGMA}\")\n",
        "print(f\"  - Color augment aktif    : {APPLY_COLOR_AUG}\")"
      ],
      "metadata": {
        "id": "LoRvI5snDSls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisis distribusi kelas & rencana balancing\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "train_counts, TRAIN_IMAGE_STATS = collect_class_stats(TRAIN_LABELS_PATH, NUM_CLASSES)\n",
        "val_counts = Counter({cls: 0 for cls in range(NUM_CLASSES)})\n",
        "test_counts = Counter({cls: 0 for cls in range(NUM_CLASSES)})\n",
        "\n",
        "if VAL_LABELS_PATH and VAL_LABELS_PATH.exists():\n",
        "    val_counts, _ = collect_class_stats(VAL_LABELS_PATH, NUM_CLASSES)\n",
        "if TEST_LABELS_PATH and TEST_LABELS_PATH.exists():\n",
        "    test_counts, _ = collect_class_stats(TEST_LABELS_PATH, NUM_CLASSES)\n",
        "\n",
        "print_class_distribution(\"Train (sebelum copy-paste)\", train_counts, CLASS_NAMES)\n",
        "if VAL_LABELS_PATH and VAL_LABELS_PATH.exists():\n",
        "    print_class_distribution(\"Validation\", val_counts, CLASS_NAMES)\n",
        "if TEST_LABELS_PATH and TEST_LABELS_PATH.exists():\n",
        "    print_class_distribution(\"Test\", test_counts, CLASS_NAMES)\n",
        "\n",
        "if TARGET_MINORITY_CLASS_NAME in CLASS_NAMES:\n",
        "    minority_class_id = CLASS_NAMES.index(TARGET_MINORITY_CLASS_NAME)\n",
        "else:\n",
        "    minority_class_id = min(train_counts, key=train_counts.get)\n",
        "majority_class_id = max(train_counts, key=train_counts.get)\n",
        "\n",
        "balance_deficit = train_counts[majority_class_id] - train_counts[minority_class_id]\n",
        "\n",
        "print(\"\\nRingkasan balancing:\")\n",
        "print(f\"Kelas mayoritas : {CLASS_NAMES[majority_class_id]} ({train_counts[majority_class_id]} instance)\")\n",
        "print(f\"Kelas minoritas : {CLASS_NAMES[minority_class_id]} ({train_counts[minority_class_id]} instance)\")\n",
        "print(f\"Selisih instance : {balance_deficit}\")\n",
        "\n",
        "AUGMENTATION_PLAN = build_balanced_augmentation_plan(\n",
        "    TRAIN_IMAGE_STATS,\n",
        "    target_class_id=minority_class_id,\n",
        "    deficit=balance_deficit,\n",
        "    max_aug_per_image=MAX_AUG_PER_IMAGE,\n",
        ")\n",
        "\n",
        "expected_new_minority = sum(\n",
        "    TRAIN_IMAGE_STATS[stem].get(minority_class_id, 0) * count\n",
        "    for stem, count in AUGMENTATION_PLAN.items()\n",
        ")\n",
        "\n",
        "print(f\"\\nRencana augmentasi untuk kelas {CLASS_NAMES[minority_class_id]}:\")\n",
        "print(f\"  - Jumlah gambar unik yang ditambah: {len(AUGMENTATION_PLAN)}\")\n",
        "print(f\"  - Total augmentasi baru: {sum(AUGMENTATION_PLAN.values())}\")\n",
        "print(f\"  - Perkiraan penambahan instance minoritas: {expected_new_minority}\")\n",
        "if balance_deficit > 0 and not AUGMENTATION_PLAN:\n",
        "    print(\"  ! Tidak ada gambar minoritas yang tersedia untuk di-augment. Dataset tetap tidak seimbang.\")\n",
        "\n",
        "BASELINE_TRAIN_COUNTS = train_counts.copy()\n",
        "MINORITY_CLASS_ID = minority_class_id\n",
        "MAJORITY_CLASS_ID = majority_class_id"
      ],
      "metadata": {
        "id": "vZSAsMKyDUAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk melakukan augmentasi copy-paste pada segmentation dataset\n",
        "def augment_segmentation_dataset(\n",
        "    images_path,\n",
        "    labels_path,\n",
        "    base_num_augmentations=0,\n",
        "    augmentation_plan=None,\n",
        "    minority_class_id=0,\n",
        "    class_names=None,\n",
        "    apply_color_aug=False,\n",
        "    mask_blur_sigma=3,\n",
        "    min_objects_per_paste=1,\n",
        "    max_objects_per_paste=3,\n",
        "    padding=4,\n",
        "):\n",
        "    \"\"\"Generate balanced data using copy-paste augmentation for YOLO segmentation.\"\"\"\n",
        "\n",
        "    images_dir = Path(images_path)\n",
        "    labels_dir = Path(labels_path)\n",
        "    augmentation_plan = augmentation_plan or {}\n",
        "\n",
        "    image_files = sorted(list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.jpeg')) + list(images_dir.glob('*.png')))\n",
        "    if not image_files:\n",
        "        print(\"Tidak ada gambar ditemukan di direktori train.\")\n",
        "        return 0\n",
        "\n",
        "    stem_to_path = {img_path.stem: img_path for img_path in image_files}\n",
        "    label_exists = {stem: (labels_dir / f\"{stem}.txt\").exists() for stem in stem_to_path}\n",
        "    base_stems = [stem for stem, exists in label_exists.items() if exists]\n",
        "\n",
        "    if not base_stems:\n",
        "        print(\"Tidak ada file label YOLO yang ditemukan. Augmentasi dibatalkan.\")\n",
        "        return 0\n",
        "\n",
        "    class_names = class_names or []\n",
        "\n",
        "    augmented_images = 0\n",
        "    total_pasted_instances = 0\n",
        "\n",
        "    # Use tqdm for progress bar\n",
        "    image_stems_to_process = [stem for stem in stem_to_path.keys() if base_num_augmentations + augmentation_plan.get(stem, 0) > 0]\n",
        "\n",
        "    for stem in tqdm(image_stems_to_process, desc=\"Applying Copy-Paste\"):\n",
        "        donor_img_path = stem_to_path[stem]\n",
        "        total_aug = base_num_augmentations + augmentation_plan.get(stem, 0)\n",
        "\n",
        "        donor_label_path = labels_dir / f\"{stem}.txt\"\n",
        "        if not donor_label_path.exists():\n",
        "            continue\n",
        "\n",
        "        donor_annotations = read_yolo_annotation(donor_label_path)\n",
        "        minority_annotations = [ann for ann in donor_annotations if int(ann[0]) == minority_class_id]\n",
        "        if not minority_annotations:\n",
        "            continue\n",
        "\n",
        "        donor_bgr = cv2.imread(str(donor_img_path))\n",
        "        if donor_bgr is None:\n",
        "            print(f\"Gagal membaca gambar donor: {donor_img_path}\")\n",
        "            continue\n",
        "        donor_rgb = cv2.cvtColor(donor_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        for aug_idx in range(total_aug):\n",
        "            base_stem = random.choice(base_stems)\n",
        "            base_img_path = stem_to_path[base_stem]\n",
        "            base_label_path = labels_dir / f\"{base_stem}.txt\"\n",
        "\n",
        "            base_annotations = read_yolo_annotation(base_label_path)\n",
        "            base_bgr = cv2.imread(str(base_img_path))\n",
        "            if base_bgr is None:\n",
        "                print(f\"Gagal membaca gambar target: {base_img_path}\")\n",
        "                continue\n",
        "            base_rgb = cv2.cvtColor(base_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            new_image = base_rgb.copy()\n",
        "            new_annotations = [list(ann) for ann in base_annotations]\n",
        "            pasted_this_image = 0\n",
        "\n",
        "            max_pick = min(max_objects_per_paste, len(minority_annotations))\n",
        "            min_pick = min(min_objects_per_paste, max_pick)\n",
        "            if max_pick <= 0 or min_pick <= 0:\n",
        "                continue\n",
        "\n",
        "            num_to_paste = random.randint(min_pick, max_pick)\n",
        "            selected_objects = random.sample(minority_annotations, num_to_paste)\n",
        "\n",
        "            for obj in selected_objects:\n",
        "                result = extract_object_patch(donor_rgb, obj[1:], padding=padding)\n",
        "                if result is None:\n",
        "                    continue\n",
        "                patch, mask_patch, polygon_local = result\n",
        "                new_polygon = paste_patch_on_base(\n",
        "                    new_image,\n",
        "                    patch,\n",
        "                    mask_patch,\n",
        "                    polygon_local,\n",
        "                    sigma=mask_blur_sigma,\n",
        "                )\n",
        "                if new_polygon is None:\n",
        "                    continue\n",
        "                new_annotations.append([obj[0]] + new_polygon)\n",
        "                pasted_this_image += 1\n",
        "                total_pasted_instances += 1\n",
        "\n",
        "            if pasted_this_image == 0:\n",
        "                continue\n",
        "\n",
        "            if apply_color_aug:\n",
        "                augmented = transform_color(image=new_image)\n",
        "                new_image = augmented['image']\n",
        "\n",
        "            base_suffix = base_img_path.suffix or '.jpg'\n",
        "            new_stem = f\"{base_stem}_cp_{stem}_{aug_idx}\"\n",
        "            unique_id = 0\n",
        "            new_image_path = images_dir / f\"{new_stem}{base_suffix}\"\n",
        "            new_label_path = labels_dir / f\"{new_stem}.txt\"\n",
        "\n",
        "            while new_image_path.exists() or new_label_path.exists():\n",
        "                unique_id += 1\n",
        "                new_stem = f\"{base_stem}_cp_{stem}_{aug_idx}_{unique_id}\"\n",
        "                new_image_path = images_dir / f\"{new_stem}{base_suffix}\"\n",
        "                new_label_path = labels_dir / f\"{new_stem}.txt\"\n",
        "\n",
        "            cv2.imwrite(str(new_image_path), cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR))\n",
        "            write_yolo_annotation(new_label_path, new_annotations)\n",
        "            augmented_images += 1\n",
        "\n",
        "    class_name = class_names[minority_class_id] if class_names and minority_class_id < len(class_names) else minority_class_id\n",
        "    print(\n",
        "        f\"\\nSelesai! Total {augmented_images} gambar baru telah dibuat dengan copy-paste.\"\n",
        "    )\n",
        "    print(\n",
        "        f\"Total instance kelas {class_name} yang ditempel: {total_pasted_instances}\"\n",
        "    )\n",
        "\n",
        "    return augmented_images\n",
        "\n",
        "print(\"Fungsi augment_segmentation_dataset copy-paste berhasil didefinisikan!\")"
      ],
      "metadata": {
        "id": "SodBEWZFDVBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jalankan augmentasi copy-paste\n",
        "print(\"Memulai proses augmentasi copy-paste dengan balancing kelas...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "augmented_count = augment_segmentation_dataset(\n",
        "    images_path=TRAIN_IMAGES_PATH,\n",
        "    labels_path=TRAIN_LABELS_PATH,\n",
        "    base_num_augmentations=DEFAULT_BASE_AUGMENTATIONS,\n",
        "    augmentation_plan=AUGMENTATION_PLAN,\n",
        "    minority_class_id=MINORITY_CLASS_ID,\n",
        "    class_names=CLASS_NAMES,\n",
        "    apply_color_aug=APPLY_COLOR_AUG,\n",
        "    mask_blur_sigma=MASK_BLUR_SIGMA,\n",
        "    min_objects_per_paste=COPY_PASTE_MIN_OBJECTS,\n",
        "    max_objects_per_paste=COPY_PASTE_MAX_OBJECTS,\n",
        "    padding=COPY_PASTE_PADDING,\n",
        ")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"Augmentasi selesai!\")\n",
        "print(f\"Total gambar baru: {augmented_count}\")"
      ],
      "metadata": {
        "id": "8U2K2PMiDWBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4: Final Verification and Visualization\n",
        "\n",
        "This section verifies the final state of the dataset after all augmentations (expansion and copy-paste) have been applied. It provides a final class distribution and visualizes a few samples to confirm the results."
      ],
      "metadata": {
        "id": "GpgHa4TDDXFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifikasi hasil augmentasi dan balancing\n",
        "train_counts_after, _ = collect_class_stats(TRAIN_LABELS_PATH, len(CLASS_NAMES))\n",
        "\n",
        "if VAL_LABELS_PATH and VAL_LABELS_PATH.exists():\n",
        "    val_counts_after, _ = collect_class_stats(VAL_LABELS_PATH, len(CLASS_NAMES))\n",
        "else:\n",
        "    val_counts_after = Counter({cls: 0 for cls in range(len(CLASS_NAMES))})\n",
        "\n",
        "if TEST_LABELS_PATH and TEST_LABELS_PATH.exists():\n",
        "    test_counts_after, _ = collect_class_stats(TEST_LABELS_PATH, len(CLASS_NAMES))\n",
        "else:\n",
        "    test_counts_after = Counter({cls: 0 for cls in range(len(CLASS_NAMES))})\n",
        "\n",
        "print(\"Statistik Dataset Setelah Semua Augmentasi Selesai:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Path dataset: {DATASET_PATH}\")\n",
        "print(f\"Train images path: {TRAIN_IMAGES_PATH}\")\n",
        "print(f\"Train labels path: {TRAIN_LABELS_PATH}\")\n",
        "\n",
        "if 'BASELINE_TRAIN_COUNTS' in globals():\n",
        "    print(\"\\nPerbandingan distribusi kelas (train):\")\n",
        "    for idx, class_name in enumerate(CLASS_NAMES):\n",
        "        before = BASELINE_TRAIN_COUNTS.get(idx, 0)\n",
        "        after = train_counts_after.get(idx, 0)\n",
        "        delta = after - before\n",
        "        sign = \"+\" if delta >= 0 else \"\"\n",
        "        print(f\"  - {class_name}: sebelum={before}, sesudah={after} ({sign}{delta})\")\n",
        "else:\n",
        "    print_class_distribution(\"Train (setelah augmentasi)\", train_counts_after, CLASS_NAMES)\n",
        "\n",
        "if VAL_LABELS_PATH and VAL_LABELS_PATH.exists():\n",
        "    print_class_distribution(\"Validation\", val_counts_after, CLASS_NAMES)\n",
        "if TEST_LABELS_PATH and TEST_LABELS_PATH.exists():\n",
        "    print_class_distribution(\"Test\", test_counts_after, CLASS_NAMES)\n",
        "\n",
        "print(\"\\nContoh file hasil augmentasi:\")\n",
        "aug_files = [\n",
        "    f for f in sorted(TRAIN_IMAGES_PATH.glob('*'))\n",
        "    if ('_aug' in f.stem or '_cp_' in f.stem) and f.suffix.lower() in {'.jpg', '.jpeg', '.png'}\n",
        "]\n",
        "for i, path in enumerate(random.sample(aug_files, min(5, len(aug_files)))):\n",
        "    print(f\"  {i+1}. {path.name}\")"
      ],
      "metadata": {
        "id": "K0y8gZO9DX0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisasi hasil augmentasi\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def visualize_augmentations(images_path, num_samples=4):\n",
        "    \"\"\"Visualisasi gambar original dan hasil augmentasinya.\"\"\"\n",
        "    images_dir = Path(images_path)\n",
        "    backup_dir = images_dir.parent.parent / 'train_original_backup' / 'images'\n",
        "\n",
        "    if not backup_dir.exists():\n",
        "        print(f\"Direktori backup gambar original tidak ditemukan: {backup_dir}\")\n",
        "        return\n",
        "\n",
        "    original_images = list(backup_dir.glob('*.jpg')) + list(backup_dir.glob('*.png'))\n",
        "\n",
        "    if not original_images:\n",
        "        print(\"Tidak ada gambar original ditemukan di backup.\")\n",
        "        return\n",
        "\n",
        "    sample_images = random.sample(original_images, min(num_samples, len(original_images)))\n",
        "\n",
        "    for orig_path in sample_images:\n",
        "        base_name = orig_path.stem\n",
        "        aug_images = list(images_dir.glob(f'{base_name}_aug*.jpg')) + \\\n",
        "                     list(images_dir.glob(f'*_cp_{base_name}*.jpg'))\n",
        "\n",
        "        if not aug_images:\n",
        "            print(f\"Tidak ada hasil augmentasi ditemukan untuk {orig_path.name}.\")\n",
        "            continue\n",
        "\n",
        "        num_cols = min(4, len(aug_images) + 1)\n",
        "        fig, axes = plt.subplots(1, num_cols, figsize=(20, 5))\n",
        "        if num_cols == 1: axes = [axes]\n",
        "\n",
        "        orig_img = Image.open(orig_path)\n",
        "        axes[0].imshow(orig_img)\n",
        "        axes[0].set_title('Original')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        for idx, aug_path in enumerate(random.sample(aug_images, min(num_cols - 1, len(aug_images)))):\n",
        "            aug_img = Image.open(aug_path)\n",
        "            axes[idx + 1].imshow(aug_img)\n",
        "            axes[idx + 1].set_title(aug_path.stem, fontsize=8)\n",
        "            axes[idx + 1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(f\"Gambar: {orig_path.name}\")\n",
        "        print(f\"  - Ditemukan {len(aug_images)} augmentasi terkait.\")\n",
        "        print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "NKIpIDBlDY2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan visualisasi hasil augmentasi\n",
        "visualize_augmentations(TRAIN_IMAGES_PATH, num_samples=2)"
      ],
      "metadata": {
        "id": "3V_hhefjDZ8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh /content/datasets"
      ],
      "metadata": {
        "id": "qERuKB_11L4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train, Val, and Predict"
      ],
      "metadata": {
        "id": "5N0dB4Y7H5zX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjust class weight before training using inverse frequency method"
      ],
      "metadata": {
        "id": "X1vkJu1jWS59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2YkphuiaE7_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "from collections import Counter\n",
        "\n",
        "# Path ke file data.yaml Anda\n",
        "data_yaml_path = f\"{dataset.location}/data.yaml\"\n",
        "\n",
        "# Muat file data.yaml\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    data_yaml = yaml.safe_load(f)\n",
        "\n",
        "# Path ke direktori label pelatihan\n",
        "train_labels_dir = os.path.join(dataset.location, 'train', 'labels')\n",
        "\n",
        "# Hitung frekuensi setiap kelas\n",
        "class_counts = Counter()\n",
        "\n",
        "if not os.path.exists(train_labels_dir):\n",
        "    print(f\"❌ Error: Training labels directory not found at {train_labels_dir}\")\n",
        "else:\n",
        "    for label_file in os.listdir(train_labels_dir):\n",
        "        if label_file.endswith('.txt'):\n",
        "            with open(os.path.join(train_labels_dir, label_file), 'r') as f:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line:  # pastikan tidak kosong\n",
        "                        class_id = int(line.split()[0])\n",
        "                        class_counts[class_id] += 1\n",
        "\n",
        "    # Hitung inverse frequency\n",
        "    num_classes = len(data_yaml.get('names', []))\n",
        "    inverse_frequencies = [0.0] * num_classes\n",
        "    for class_id, count in class_counts.items():\n",
        "        if class_id < num_classes:\n",
        "            inverse_frequencies[class_id] = 1.0 / count if count > 0 else 0.0\n",
        "\n",
        "    # Normalisasi dengan skala bobot terkecil = 1\n",
        "    positive_weights = [w for w in inverse_frequencies if w > 0]\n",
        "    min_weight = min(positive_weights) if positive_weights else 1.0\n",
        "    class_weights = [round(w / min_weight, 4) if w > 0 else 0.0 for w in inverse_frequencies]\n",
        "\n",
        "    # Tambahkan bobot kelas ke data.yaml\n",
        "    data_yaml['weights'] = class_weights\n",
        "\n",
        "    # Simpan kembali file data.yaml\n",
        "    with open(data_yaml_path, 'w') as f:\n",
        "        yaml.safe_dump(data_yaml, f, sort_keys=False)\n",
        "\n",
        "    print(f\"✅ Bobot kelas (skala terkecil=1) telah ditambahkan ke {data_yaml_path}\\n\")\n",
        "    print(f\"📊 Bobot Kelas (Min=1): {class_weights}\")\n",
        "\n",
        "    # Tampilkan isi file data.yaml setelah modifikasi\n",
        "    print(\"\\n📄 Isi data.yaml setelah update:\")\n",
        "    with open(data_yaml_path, 'r') as f:\n",
        "        print(f.read())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_hyp = dict(\n",
        "    task=\"segment\",\n",
        "    data=f\"{dataset.location}/data.yaml\",\n",
        "    epochs=2500,\n",
        "    imgsz=640,\n",
        "    plots=True,\n",
        "    hsv_h=0.0,\n",
        "    hsv_s=0.0,\n",
        "    hsv_v=0.0,\n",
        "    degrees=0.0,\n",
        "    translate=0.0,\n",
        "    scale=0.0,\n",
        "    shear=0.0,\n",
        "    perspective=0.0,\n",
        "    flipud=0.0,\n",
        "    fliplr=0.0,\n",
        "    bgr=0.0,\n",
        "    mosaic=0.4,\n",
        "    mixup=0.0,\n",
        "    cutmix=0.3,\n",
        "    copy_paste=0.3,\n",
        "    copy_paste_mode=\"mixup\",\n",
        "\n",
        "    lr0=0.01047,\n",
        "    lrf=0.0075,\n",
        "    momentum=0.80434,\n",
        "    weight_decay=0.00102,\n",
        "    box=9.0594,\n",
        "    cls=0.48542,\n",
        "    dfl=2.62724,\n",
        "    warmup_epochs=2.55604,\n",
        "    warmup_momentum=0.87073,\n",
        "    close_mosaic=11.0\n",
        ")"
      ],
      "metadata": {
        "id": "d885nMRLX8oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}"
      ],
      "metadata": {
        "id": "TxLtMsucxcxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mini-Training (Optional)"
      ],
      "metadata": {
        "id": "2eE8GsxsL5-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import shutil, time\n",
        "from copy import deepcopy\n",
        "\n",
        "model = YOLO(\"yolo11m-seg.pt\")\n",
        "\n",
        "# Make a copy of the original training hyperparameters\n",
        "mini_train_hyp = deepcopy(train_hyp)\n",
        "\n",
        "# Override specific parameters for mini training\n",
        "mini_train_hyp['epochs'] = 30\n",
        "mini_train_hyp['imgsz'] = 1280\n",
        "mini_train_hyp['batch'] = -1\n",
        "mini_train_hyp['name'] = 'mini_train'\n",
        "\n",
        "# Train with modified hyperparameters\n",
        "model.train(**mini_train_hyp)"
      ],
      "metadata": {
        "id": "F6dHF7V8MjYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full Training"
      ],
      "metadata": {
        "id": "isBfE7AZL-xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import shutil, time\n",
        "\n",
        "model = YOLO(\"yolo11m-seg.pt\")\n",
        "\n",
        "# Cache last best file seen\n",
        "last_best = {\"path\": None, \"mtime\": None}\n",
        "\n",
        "def save_best(trainer):\n",
        "    best_path = trainer.best\n",
        "    if best_path and os.path.exists(best_path):\n",
        "        mtime = os.path.getmtime(best_path)\n",
        "        if best_path != last_best[\"path\"] or mtime != last_best[\"mtime\"]:\n",
        "            # Update cache\n",
        "            last_best[\"path\"] = best_path\n",
        "            last_best[\"mtime\"] = mtime\n",
        "\n",
        "            # Fixed destination folder (always overwrite)\n",
        "            dst = f\"/content/drive/MyDrive/{RUNS_FOLDER_NAME}/checkpoints\"\n",
        "            shutil.copytree(\"/content/runs\", dst, dirs_exist_ok=True)\n",
        "\n",
        "            # Grab training details\n",
        "            best_fitness = getattr(trainer, \"best_fitness\", None)\n",
        "            loss_names   = getattr(trainer, \"loss_names\", None)\n",
        "            metrics      = getattr(trainer, \"metrics\", None)\n",
        "            total_loss   = getattr(trainer, \"tloss\", None)\n",
        "\n",
        "            # Print summary\n",
        "            print(\"✅ runs folder uploaded →\", dst)\n",
        "            print(\"\\nModel details:\")\n",
        "            print(f\"  Best fitness: {best_fitness}\")\n",
        "            print(f\"  Total loss: {total_loss}\")\n",
        "            print(f\"  Loss names: {loss_names}\\n\")\n",
        "\n",
        "            print(\"  Metrics:\")\n",
        "            if isinstance(metrics, dict):\n",
        "                for key, value in metrics.items():\n",
        "                    print(f\"    {key}: {value}\")\n",
        "            elif isinstance(metrics, (list, tuple)):\n",
        "                for i, value in enumerate(metrics):\n",
        "                    print(f\"    [{i}] {value}\")\n",
        "            else:\n",
        "                print(f\"    {metrics}\")\n",
        "\n",
        "\n",
        "# Register callback\n",
        "model.add_callback(\"on_fit_epoch_end\", save_best)\n",
        "\n",
        "# Train\n",
        "model.train(**train_hyp)"
      ],
      "metadata": {
        "id": "925FXqe6xUlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mkT-rUhqQLp"
      },
      "source": [
        "**NOTE:** The results of the completed training are saved in `{HOME}/runs/detect/train/`. Let's examine them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MScstfHhArr"
      },
      "outputs": [],
      "source": [
        "!ls {HOME}/runs/segment/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J35i8Ofhjxa"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "IPyImage(filename=f'{HOME}/runs/segment/train/confusion_matrix.png', width=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-urTWUkhRmn"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "IPyImage(filename=f'{HOME}/runs/segment/train/results.png', width=1400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI4nADCCj3F5"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "IPyImage(filename=f'{HOME}/runs/segment/train/val_batch0_pred.jpg', width=1400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ODk1VTlevxn"
      },
      "source": [
        "## Validate fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(f\"{HOME}/runs/segment/train/weights/best.pt\")  # load a custom model\n",
        "\n",
        "# Validate the model\n",
        "metrics = model.val(\n",
        "    task=\"segment\",\n",
        "    data=f\"{dataset.location}/data.yaml\",\n",
        "    imgsz=640,\n",
        "    max_det=1000,\n",
        "    plots=False,\n",
        "    visualize=True\n",
        ")"
      ],
      "metadata": {
        "id": "iGRNOCacDBDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val(\n",
        "    task=\"segment\",\n",
        "    data=f\"{dataset.location}/data.yaml\",\n",
        "    imgsz=640,\n",
        "    max_det=1000,\n",
        "    plots=True,\n",
        "    visualize=False\n",
        ")"
      ],
      "metadata": {
        "id": "kv4w2FyWF6zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.box.map  # map50-95"
      ],
      "metadata": {
        "id": "mUYG0pyjDUen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.box.map50  # map50"
      ],
      "metadata": {
        "id": "btzxyoJYDVqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.box.map75  # map75"
      ],
      "metadata": {
        "id": "Yz0nterADWcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.box.maps  # a list contains map50-95 of each category"
      ],
      "metadata": {
        "id": "qEC78LaoDXcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpyuwrNlXc1P"
      },
      "outputs": [],
      "source": [
        "# !yolo task=segment mode=val model={HOME}/runs/segment/train/weights/best.pt data={dataset.location}/data.yaml imgsz=640 plots=True max_det=1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "## Inference with custom model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(f\"{HOME}/runs/segment/train/weights/best.pt\")  # load a custom model"
      ],
      "metadata": {
        "id": "0p3Xg0-SGWTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(\n",
        "    task=\"segment\",\n",
        "    source=f\"{dataset.location}/test/images\",\n",
        "    imgsz=640,\n",
        "    conf=0.5,\n",
        "    iou=0.5,\n",
        "    max_det=1000,\n",
        "    visualize=True,\n",
        "    save=True,\n",
        "    show_labels=False,\n",
        "    show_conf=False\n",
        ")"
      ],
      "metadata": {
        "id": "usZfwlgaGZ1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wjc1ctZykYuf"
      },
      "outputs": [],
      "source": [
        "# !yolo task=segment mode=predict model={HOME}/runs/segment/train/weights/best.pt imgsz=640 source={dataset.location}/test/images save=True conf=0.5 iou=0.5 max_det=1000 visualize=True show=True save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEYIo95n-I0S"
      },
      "source": [
        "**NOTE:** Let's take a look at few results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nOnTQynZfeA"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from IPython.display import Image as IPyImage, display\n",
        "\n",
        "latest_folder = max(glob.glob(f'{HOME}/runs/segment/predict*/'), key=os.path.getmtime)\n",
        "for img in glob.glob(f'{latest_folder}/*.jpg')[:3]:\n",
        "    display(IPyImage(filename=img, width=600))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNtkJoCq0evb"
      },
      "outputs": [],
      "source": [
        "!ls runs/segment/predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4HcH8Px0jj_"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from IPython.display import Image as IPyImage, display\n",
        "\n",
        "latest_folder = max(glob.glob(f'{HOME}/runs/segment/predict/'), key=os.path.getmtime)\n",
        "for img in glob.glob(f'{latest_folder}/*.jpg')[17:18]:\n",
        "    print(img)\n",
        "    display(IPyImage(filename=img, width=600))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBi_Fi462Eni"
      },
      "outputs": [],
      "source": [
        "# # ls /content/runs/segment/predict/flare_0014_jpg.rf.dc43f1770f6dd479c527fb2f05bfc849.jpg\n",
        "# !ls /content/datasets/Fire-and-Smoke-Segmentation-1/test/images/flare_0014_jpg.rf.dc43f1770f6dd479c527fb2f05bfc849.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg5GKvjv2efh"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "model = YOLO(f'{HOME}/runs/segment/train/weights/best.pt')\n",
        "image = Image.open(f\"/content/datasets/Rice-Grain-{VERSION}/test/images/EarBlast104-3-_jpg.rf.a21e421cf85a705dd6139fa76ee05e62.jpg\")\n",
        "result = model.predict(image, conf=0.5)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAgEF_7v2f3J"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "detections = sv.Detections.from_ultralytics(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWzRBYfR2gle"
      },
      "outputs": [],
      "source": [
        "mask_annotator = sv.MaskAnnotator()\n",
        "\n",
        "annotated_image = image.copy()\n",
        "mask_annotator.annotate(annotated_image, detections=detections)\n",
        "\n",
        "sv.plot_image(annotated_image, size=(10, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Final Results to Drive"
      ],
      "metadata": {
        "id": "gY_yspeLSqXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_full_runs():\n",
        "    src = \"/content/runs\"\n",
        "    dst = f\"/content/drive/MyDrive/{RUNS_FOLDER_NAME}/final_results\"\n",
        "    shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "    print(f\"📦 Full training runs copied to: {dst}\")"
      ],
      "metadata": {
        "id": "rBFGIFXjT2Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_full_runs()"
      ],
      "metadata": {
        "id": "gkOXvuPyT4iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, glob, os\n",
        "\n",
        "# === Destination folder in Drive ===\n",
        "dst_dir = f\"/content/drive/MyDrive/{RUNS_FOLDER_NAME}\"\n",
        "os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "# === Find the current notebook in /content ===\n",
        "notebooks = glob.glob(\"/content/*.ipynb\")\n",
        "\n",
        "if notebooks:\n",
        "    notebook_path = notebooks[0]  # usually just one notebook\n",
        "    dst_path = os.path.join(dst_dir, os.path.basename(notebook_path))\n",
        "\n",
        "    shutil.copy2(notebook_path, dst_path)\n",
        "    print(f\"📘 Notebook saved (overwritten if existed): {dst_path}\")\n",
        "else:\n",
        "    print(\"⚠️ No notebook found in /content to upload.\")\n"
      ],
      "metadata": {
        "id": "vIR5x18FSmAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Catat waktu selesai\n",
        "end_time = time.time()\n",
        "\n",
        "# Hitung total waktu berjalan dalam detik\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "# Konversi detik ke jam, menit, dan detik\n",
        "hours = int(elapsed_time // 3600)\n",
        "minutes = int((elapsed_time % 3600) // 60)\n",
        "seconds = int(elapsed_time % 60)\n",
        "\n",
        "print(f\"\\n🎉 Script Selesai!\")\n",
        "print(f\"Total Waktu Berjalan: {hours} jam, {minutes} menit, {seconds} detik.\")"
      ],
      "metadata": {
        "id": "6ag6bmahUPHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqrZUG5e2_It"
      },
      "source": [
        "# 🏆 Congratulations\n",
        "\n",
        "### Learning Resources\n",
        "\n",
        "Roboflow has produced many resources that you may find interesting as you advance your knowledge of computer vision:\n",
        "\n",
        "- [Roboflow Notebooks](https://github.com/roboflow/notebooks): A repository of over 20 notebooks that walk through how to train custom models with a range of model types, from YOLOv7 to SegFormer.\n",
        "- [Roboflow YouTube](https://www.youtube.com/c/Roboflow): Our library of videos featuring deep dives into the latest in computer vision, detailed tutorials that accompany our notebooks, and more.\n",
        "- [Roboflow Discuss](https://discuss.roboflow.com/): Have a question about how to do something on Roboflow? Ask your question on our discussion forum.\n",
        "- [Roboflow Models](https://roboflow.com): Learn about state-of-the-art models and their performance. Find links and tutorials to guide your learning.\n",
        "\n",
        "### Convert data formats\n",
        "\n",
        "Roboflow provides free utilities to convert data between dozens of popular computer vision formats. Check out [Roboflow Formats](https://roboflow.com/formats) to find tutorials on how to convert data between formats in a few clicks.\n",
        "\n",
        "### Connect computer vision to your project logic\n",
        "\n",
        "[Roboflow Templates](https://roboflow.com/templates) is a public gallery of code snippets that you can use to connect computer vision to your project logic. Code snippets range from sending emails after inference to measuring object distance between detections."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}